{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-11T07:08:20.062286Z",
     "start_time": "2025-01-11T07:07:33.684390300Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, AutoPeftModelForCausalLM, TaskType, PeftModel\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, set_seed, Trainer, TrainingArguments, BitsAndBytesConfig, \\\n",
    "    DataCollatorForLanguageModeling, Trainer, TrainingArguments, logging, pipeline\n",
    "from torch import cuda, bfloat16\n",
    "import transformers\n",
    "from trl import DataCollatorForCompletionOnlyLM, SFTConfig, SFTTrainer\n",
    "import pandas as pd\n",
    "from textwrap import dedent\n",
    "from datasets import Dataset, load_dataset\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "from metrics import  calculate_metrics, calculate_metrics2, calc_mets_my\n",
    "import gc\n",
    "import sys\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "PROJECT = \"Llama3-8B-QLora-FineTune-Omni\"\n",
    "MODEL_NAME = 'meta-llama/Meta-Llama-3-8B-Instruct'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-11T07:08:20.078287900Z",
     "start_time": "2025-01-11T07:08:20.064288700Z"
    }
   },
   "id": "8a2b7e3486d63697",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=bfloat16\n",
    ")\n",
    "\n",
    "\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    token=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-11T07:08:20.475285700Z",
     "start_time": "2025-01-11T07:08:20.070287500Z"
    }
   },
   "id": "4bb0e1409fa5d683",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=64,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\n",
    "        \"self_attn.q_proj\",\n",
    "        \"self_attn.k_proj\",\n",
    "        \"self_attn.v_proj\",\n",
    "        \"self_attn.o_proj\",\n",
    "        \"mlp.gate_proj\",\n",
    "        \"mlp.up_proj\",\n",
    "        \"mlp.down_proj\",\n",
    "    ],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-11T07:08:20.489284900Z",
     "start_time": "2025-01-11T07:08:20.479285100Z"
    }
   },
   "id": "37ec968f0cd5a103",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for  param in model.parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-11T07:22:53.072698900Z",
     "start_time": "2025-01-11T07:22:53.046699100Z"
    }
   },
   "id": "6389c74e9c9be294",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "58d5a25e1b3143c7b0fcc40a18f52d27"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model........\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        trust_remote_code=True,\n",
    "        config=model_config,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map='auto',\n",
    "        token=True\n",
    "    )\n",
    "print(\"loaded model........\")\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-11T07:21:45.141363100Z",
     "start_time": "2025-01-11T07:20:46.586982800Z"
    }
   },
   "id": "de6eed928449981a",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1050939392 || all params: 4540600320 || trainable%: 23.145384264959926\n"
     ]
    }
   ],
   "source": [
    "print_trainable_parameters(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-11T07:22:57.670679500Z",
     "start_time": "2025-01-11T07:22:57.635681400Z"
    }
   },
   "id": "1d6fb3f83121ff19",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4708372480\n"
     ]
    }
   ],
   "source": [
    "num_parameters = sum(p.numel() for p in model.parameters())\n",
    "print(num_parameters)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-11T07:27:28.087136700Z",
     "start_time": "2025-01-11T07:27:28.074137600Z"
    }
   },
   "id": "18e0c689d289f1af",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, lora_config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-11T07:27:18.582099400Z",
     "start_time": "2025-01-11T07:27:15.391115300Z"
    }
   },
   "id": "f028555579bb554c",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 167772160 || all params: 4708372480 || trainable%: 3.5632728870252848\n"
     ]
    }
   ],
   "source": [
    "print_trainable_parameters(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-11T07:27:19.587635900Z",
     "start_time": "2025-01-11T07:27:19.577633500Z"
    }
   },
   "id": "954369bb221d87da",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-11T07:20:39.632929800Z",
     "start_time": "2025-01-11T07:20:38.659395900Z"
    }
   },
   "id": "7eb37e8e3e9d9de2",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def format_test(row: dict, scenario='fine-tune'):\n",
    "    prompt = dedent(\n",
    "        f\"\"\"\n",
    "        Place 1: '{row[\"e1\"]}'\n",
    "        Place 2: '{row[\"e2\"]}'\n",
    "        \n",
    "    \"\"\"\n",
    "    )\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "    if scenario==\"zero\":\n",
    "        full_prompt = messages[0][\"content\"] + prompt + \"Answer: \"\n",
    "        return full_prompt\n",
    "    else:\n",
    "        return tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-08T23:50:36.185588900Z",
     "start_time": "2025-01-08T23:50:36.181587600Z"
    }
   },
   "id": "fe089cab062840d7",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def format_test_distance(row, scenario=\"fine-tune\"):\n",
    "    prompt = dedent(\n",
    "        f\"\"\"\n",
    "        Place1: '{row[\"e1\"]}'\n",
    "        Place2: '{row[\"e2\"]}'\n",
    "        Distance: {row['distance']}\n",
    "    \n",
    "    \"\"\"\n",
    "    )\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\":  \"Two place descriptions and the geographic distance between them is provided. Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "    if scenario==\"zero\":\n",
    "        full_prompt = messages[0][\"content\"] + prompt + \"Answer:\"\n",
    "        return full_prompt\n",
    "    else:\n",
    "        return tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-08T23:50:36.217588Z",
     "start_time": "2025-01-08T23:50:36.189589800Z"
    }
   },
   "id": "dff2825e9fcbb229",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def format_test_gtminer(row: dict, scenario):\n",
    "    prompt = dedent(\n",
    "        f\"\"\"\n",
    "    Place 1: '{row[\"e1\"]}'\n",
    "    Place 2: '{row[\"e2\"]}'\n",
    "    \n",
    "    \"\"\"\n",
    "    )\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Two place descriptions are provided. Answer with 'same_as' if the first place is the same as the second place. Answer with 'part_of' if the first place is a part of the second place and is located inside the second place. Answer with 'serves' if the first place provides a service to the second place in terms of human mobility, assistance, etc. Answer with 'unknown' if the two places show none of these relations.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "    \n",
    "    if scenario==\"zero\":\n",
    "        full_prompt = messages[0][\"content\"] + prompt + \"Answer: \"\n",
    "        return full_prompt\n",
    "    else:\n",
    "        return tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-08T23:50:36.218597100Z",
     "start_time": "2025-01-08T23:50:36.197589400Z"
    }
   },
   "id": "e1dc7cb63e95a4c",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def format_test_gtminer_simple(row: dict, scenario):\n",
    "    prompt = dedent(\n",
    "        f\"\"\"\n",
    "    Place 1: '{row[\"e1\"]}'\n",
    "    Place 2: '{row[\"e2\"]}'\n",
    "    \n",
    "    \"\"\"\n",
    "    )\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Two place descriptions are provided. Predict the relation between them. Answer only with ‘same_as’, ‘part_of’, ‘serves’ or ‘unknown’\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "    \n",
    "    if scenario==\"zero\":\n",
    "        full_prompt = messages[0][\"content\"] + prompt + \"Answer:\"\n",
    "        return full_prompt\n",
    "    else:\n",
    "        return tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-08T23:50:47.583562900Z",
     "start_time": "2025-01-08T23:50:47.559563400Z"
    }
   },
   "id": "afe8fe42e673a14e",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def format_test_gtminer_distance(row: dict, scenario=\"fine-tune\"):\n",
    "    prompt = dedent(\n",
    "        f\"\"\"\n",
    "    Place 1: '{row[\"e1\"]}'\n",
    "    Place 2: '{row[\"e2\"]}'\n",
    "    Distance: {row[\"distance\"]}\n",
    "    Answer only with: same_as, part_of, serves, unknown\n",
    "    \n",
    "    \"\"\"\n",
    "    )\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Two place descriptions and the geographic distance between them is provided. Answer with 'same_as' if the first place is the same as the second place. Answer with 'part_of' if the first place is a part of the second place and is located inside the second place. Answer with 'serves' if the first place provides a service to the second place in terms of human mobility, assistance, etc. Answer with 'unknown' if the two places show none of these relations.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "    \n",
    "    if scenario==\"zero\":\n",
    "        full_prompt = messages[0][\"content\"] + prompt + \"Answer: \"\n",
    "        return full_prompt\n",
    "    else:\n",
    "        return tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-08T23:51:00.511606900Z",
     "start_time": "2025-01-08T23:51:00.488607100Z"
    }
   },
   "id": "bce2b392b4660360",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def format_test_gtminer2(row: dict, scenario=\"fine-tune\"):\n",
    "    prompt = dedent(\n",
    "        f\"\"\"\n",
    "        Place 1: '{row[\"e1\"]}'\n",
    "        Place 2: '{row[\"e2\"]}'\n",
    "        Answer only with: same_as, part_of, serves, unknown\n",
    "    \"\"\"\n",
    "    )\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Two place descriptions are provided. Answer with 'same_as' if the first place is the same as the second place. Answer with 'part_of' if the first place is a part of the second place and is located inside the second place. Answer with 'serves' if the first place provides a service to the second place in terms of human mobility, assistance, etc. Answer with 'unknown' if the two places show none of these relations.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "    if scenario==\"zero\":\n",
    "        full_prompt = messages[0][\"content\"] + prompt + \"Answer: \"\n",
    "        return full_prompt\n",
    "    else:\n",
    "        return tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-08T23:51:03.563597200Z",
     "start_time": "2025-01-08T23:51:03.549597400Z"
    }
   },
   "id": "14bc1ec073594afb",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def format_test_gtminer3(row: dict, scenario=\"fine-tune\"):\n",
    "    prompt = dedent(\n",
    "        f\"\"\"\n",
    "    Place 1: '{row[\"e1\"]}'\n",
    "    Place 2: '{row[\"e2\"]}'\n",
    "    Answer only with: same-as, part-of, serves, unknown\n",
    "    \"\"\"\n",
    "    )\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Two place descriptions are provided. Predict the relation between the two places.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "    \n",
    "    if scenario==\"zero\":\n",
    "        full_prompt = messages[0][\"content\"] + prompt + \"Answer: \"\n",
    "        return full_prompt\n",
    "    else:\n",
    "        return tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-08T23:51:07.059587200Z",
     "start_time": "2025-01-08T23:51:07.036591500Z"
    }
   },
   "id": "3c6e94375e4762da",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataset_folder_path = ['datasets\\\\my_data_plm\\\\auck\\\\', 'datasets\\\\my_data_plm\\\\hope\\\\', 'datasets\\\\my_data_plm\\\\norse\\\\','datasets\\\\my_data_plm\\\\north\\\\', 'datasets\\\\my_data_plm\\\\palm\\\\', 'datasets\\\\osm_fsq_plm\\\\edi\\\\', 'datasets\\\\osm_fsq_plm\\\\pit\\\\', 'datasets\\\\osm_fsq_plm\\\\sin\\\\', 'datasets\\\\osm_fsq_plm\\\\tor\\\\', 'datasets\\\\osm_yelp_plm\\\\edi\\\\', 'datasets\\\\osm_yelp_plm\\\\pit\\\\', 'datasets\\\\osm_yelp_plm\\\\sin\\\\', 'datasets\\\\osm_yelp_plm\\\\tor\\\\', 'datasets\\\\acheson_plm\\\\swiss\\\\']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-08T23:51:10.897109100Z",
     "start_time": "2025-01-08T23:51:10.877105900Z"
    }
   },
   "id": "f15d95676ed53885",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['datasets', 'my_data_plm', 'auck', '']\n",
      "successfully loaded dataset.......\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fff54e5dfce94b78a4ad41556410d553"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model........\n",
      "loaded tokenizer........\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Place1: 'COL name VAL Gusto at the Grand COL type VAL restaurant COL latitude VAL -36.8493632 COL longitude VAL 174.762685 '\n",
      "Place2: 'COL name VAL Federal Delicatessen COL type VAL restaurant COL latitude VAL -36.8489282 COL longitude VAL 174.7624718 '<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "No<|eot_id|>\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.\n",
      "Place 1: 'COL name VAL Tautini COL type VAL farmstead COL latitude VAL -40.18825 COL longitude VAL 176.14021 '\n",
      "Place 2: 'COL name VAL Waikoukou Stream COL type VAL Stream COL latitude VAL -40.08742665596005 COL longitude VAL 176.28878276483226 '\n",
      "\n",
      "Answer: \n",
      "testing completed........\n",
      "['datasets', 'my_data_plm', 'auck', '']\n",
      "{'Precision': 0.8571428571428571, 'Recall': 0.3, 'F1 Score': 0.4444444444444444}\n",
      "{'Precision': 0.8571428571428571, 'Recall': 0.3, 'F1 Score': 0.4444444444444444}\n",
      "{'Precision': 0.9750415973377704, 'Recall': 0.9750415973377704, 'F1 Score': 0.9750415973377704}\n",
      "{'Precision': 0.9167869167869167, 'Recall': 0.6491394148020654, 'F1 Score': 0.7158392434988179}\n",
      "['datasets', 'my_data_plm', 'hope', '']\n"
     ]
    },
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fc00355b9c67461cb7c79ef47186810d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating valid split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ee03cc2e7a8843e7ab896f12213affd4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating test split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a11b43e9adf54fc1834207e5dd4631e7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully loaded dataset.......\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "081779f5a6bc489791ab86ea2f16dae3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model........\n",
      "loaded tokenizer........\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Place1: 'COL name VAL McKay Creek COL type VAL stream COL latitude VAL -44.21667 COL longitude VAL 168.43333 '\n",
      "Place2: 'COL name VAL Gipsy Creek COL type VAL Stream COL latitude VAL -44.022242 COL longitude VAL 168.684074 '<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "No<|eot_id|>\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.\n",
      "Place 1: 'COL name VAL Silver Stream COL type VAL stream COL latitude VAL -44.04833 COL longitude VAL 168.67008 '\n",
      "Place 2: 'COL name VAL Deep Dale COL type VAL Valley COL latitude VAL -44.025083 COL longitude VAL 168.672056 '\n",
      "\n",
      "Answer: \n",
      "testing completed........\n",
      "['datasets', 'my_data_plm', 'hope', '']\n",
      "{'Precision': 0.8571428571428571, 'Recall': 0.05357142857142857, 'F1 Score': 0.10084033613445377}\n",
      "{'Precision': 0.8571428571428571, 'Recall': 0.05357142857142857, 'F1 Score': 0.10084033613445378}\n",
      "{'Precision': 0.9631922944616443, 'Recall': 0.9631922944616443, 'F1 Score': 0.9631922944616443}\n",
      "{'Precision': 0.910295566502463, 'Recall': 0.526606823409149, 'F1 Score': 0.5410259626238555}\n",
      "['datasets', 'my_data_plm', 'norse', '']\n"
     ]
    },
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c72152ca56994420a7e85acc4eecdee9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating valid split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3612f536ef334c82a825094235990103"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating test split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2d63fa85d6234bbfb96c4553bcffe9a8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully loaded dataset.......\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a85a14e5a48a4b3990d50e08029d018c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model........\n",
      "loaded tokenizer........\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Place1: 'COL name VAL Whenuahou Road COL type VAL Road COL latitude VAL -40.06161022305828 COL longitude VAL 176.2735663066924 '\n",
      "Place2: 'COL name VAL Edgecombe Road COL type VAL residential COL latitude VAL -40.09448984256211 COL longitude VAL 176.28856526803682 '<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "No<|eot_id|>\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.\n",
      "Place 1: 'COL name VAL Mangatewai River Scenic Reserve COL type VAL Scenic Reserve COL latitude VAL -39.985556 COL longitude VAL 176.254722 '\n",
      "Place 2: 'COL name VAL Ōtāwhao COL type VAL locality COL latitude VAL -40.0501529 COL longitude VAL 176.2682748 '\n",
      "\n",
      "Answer: \n",
      "testing completed........\n",
      "['datasets', 'my_data_plm', 'norse', '']\n",
      "{'Precision': 0.6666666666666666, 'Recall': 0.044444444444444446, 'F1 Score': 0.08333333333333334}\n",
      "{'Precision': 0.6666666666666666, 'Recall': 0.044444444444444446, 'F1 Score': 0.08333333333333333}\n",
      "{'Precision': 0.9753224901850813, 'Recall': 0.9753224901850813, 'F1 Score': 0.9753224901850813}\n",
      "{'Precision': 0.82125468164794, 'Recall': 0.5219345352256745, 'F1 Score': 0.5354131135114648}\n",
      "['datasets', 'my_data_plm', 'north', '']\n"
     ]
    },
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "596828e2d6604d0098e0b31c900d5d01"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating valid split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b7c3465499f7432d803b9c1eeb9a16ce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating test split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6c13e7878e804f44b1ca802443cfa0e3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully loaded dataset.......\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a73c73b086846c48b1931015a63941e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model........\n",
      "loaded tokenizer........\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Place1: 'COL name VAL Te Hapua Road COL type VAL Road COL latitude VAL -34.507622187539326 COL longitude VAL 172.879036032542 '\n",
      "Place2: 'COL name VAL Spirits Bay Road COL type VAL Road COL latitude VAL -34.462798484674664 COL longitude VAL 172.87382978145064 '<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "No<|eot_id|>\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.\n",
      "Place 1: 'COL name VAL Waitiki Channel COL type VAL stream COL latitude VAL -34.51818 COL longitude VAL 172.88018 '\n",
      "Place 2: 'COL name VAL Matapia COL type VAL Island COL latitude VAL -34.606333571762384 COL longitude VAL 172.79844153380557 '\n",
      "\n",
      "Answer: \n",
      "testing completed........\n",
      "['datasets', 'my_data_plm', 'north', '']\n",
      "{'Precision': 0.8571428571428571, 'Recall': 0.14285714285714285, 'F1 Score': 0.24489795918367344}\n",
      "{'Precision': 0.8571428571428571, 'Recall': 0.14285714285714285, 'F1 Score': 0.24489795918367346}\n",
      "{'Precision': 0.9678447276940904, 'Recall': 0.9678447276940904, 'F1 Score': 0.9678447276940904}\n",
      "{'Precision': 0.9128325769246783, 'Recall': 0.5709775792457693, 'F1 Score': 0.6142352752851917}\n",
      "['datasets', 'my_data_plm', 'palm', '']\n"
     ]
    },
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ee021e190fa547d9b6f60f0f34d6f0ea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating valid split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d174bd61e3c548a1ad6a79e1a0b305b1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating test split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "73649df7cc7a4ad4802e064c28aaa84d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully loaded dataset.......\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "29282c96901c4c5bb4587147e1d6230f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model........\n",
      "loaded tokenizer........\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Place1: 'COL name VAL Burns Avenue COL type VAL Avenue COL latitude VAL -40.36030449934024 COL longitude VAL 175.59693070851543 '\n",
      "Place2: 'COL name VAL Burns Avenue COL type VAL residential COL latitude VAL -40.36031171459725 COL longitude VAL 175.59695386064422 '<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Yes<|eot_id|>\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.\n",
      "Place 1: 'COL name VAL Guy Avenue COL type VAL residential COL latitude VAL -40.34778395292905 COL longitude VAL 175.6002199480078 '\n",
      "Place 2: 'COL name VAL Argyle Avenue COL type VAL residential COL latitude VAL -40.34934954465575 COL longitude VAL 175.60141052181092 '\n",
      "\n",
      "Answer: \n",
      "testing completed........\n",
      "['datasets', 'my_data_plm', 'palm', '']\n",
      "{'Precision': 1.0, 'Recall': 0.05263157894736842, 'F1 Score': 0.1}\n",
      "{'Precision': 1.0, 'Recall': 0.05263157894736842, 'F1 Score': 0.1}\n",
      "{'Precision': 0.9697732997481109, 'Recall': 0.9697732997481109, 'F1 Score': 0.9697732997481109}\n",
      "{'Precision': 0.9848612279226241, 'Recall': 0.5263157894736842, 'F1 Score': 0.5423142613151153}\n",
      "['datasets', 'osm_fsq_plm', 'edi', '']\n"
     ]
    },
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e955bbc54d3844a2a1b2a337daa53233"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating valid split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9cd6e0e1aa5c4be0bc9a95c2746cd99a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating test split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "35a9cc94d0e245acaeb14607275694e9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully loaded dataset.......\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2264b833e9e54d0c9cf65903ae047f9d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model........\n",
      "loaded tokenizer........\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Place1: 'COL name VAL Cafe Royal COL latitude VAL 55.9540951 COL longitude VAL -3.1904838 COL address VAL West Register Street, 19 COL postalCode VAL EH2 2AA '\n",
      "Place2: 'COL name VAL C Royale COL latitude VAL 55.953308 COL longitude VAL -3.197555 COL address VAL 22 George Street COL postalCode VAL EH2 '<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "No<|eot_id|>\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.\n",
      "Place 1: 'COL name VAL Grace North Edinburgh COL latitude VAL 55.96494943189891 COL longitude VAL -3.196916036169164 COL address VAL Logie Green Rd, 64 COL postalCode VAL EH7 4HQ '\n",
      "Place 2: 'COL name VAL Crombies of Edinburgh COL latitude VAL 55.95861906805779 COL longitude VAL -3.19005780781009 COL address VAL 97-101 Broughton St COL postalCode VAL EH1 3RZ '\n",
      "\n",
      "Answer: \n",
      "testing completed........\n",
      "['datasets', 'osm_fsq_plm', 'edi', '']\n",
      "{'Precision': 0.9340659340659341, 'Recall': 0.0845771144278607, 'F1 Score': 0.1551094890510949}\n",
      "{'Precision': 0.9340659340659341, 'Recall': 0.0845771144278607, 'F1 Score': 0.1551094890510949}\n",
      "{'Precision': 0.8224693251533742, 'Recall': 0.8224693251533742, 'F1 Score': 0.8224693251533742}\n",
      "{'Precision': 0.8772768694719915, 'Recall': 0.5415761373611638, 'F1 Score': 0.5279617710893864}\n",
      "['datasets', 'osm_fsq_plm', 'pit', '']\n"
     ]
    },
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3f0a4e528601488aa92d3de515bc8624"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating valid split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3d1fbe7871ad43bda1d92c9c4bec9266"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating test split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "811a76a486f44c10972a18812025c152"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully loaded dataset.......\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6d5db038402941ca9edc1c6499b9bb7d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model........\n",
      "loaded tokenizer........\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Place1: 'COL name VAL 1909 McKee's Rocks Strike COL latitude VAL 40.4760582 COL longitude VAL -80.0601889 COL address VAL nan COL postalCode VAL nan '\n",
      "Place2: 'COL name VAL McKees Rocks Bridge COL latitude VAL 40.47708444297618 COL longitude VAL -80.04827499389648 COL address VAL Mckees Rocks Bridge, Route 65 COL postalCode VAL 15233 '<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "No<|eot_id|>\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.\n",
      "Place 1: 'COL name VAL Panther Hall COL latitude VAL 40.44498734340524 COL longitude VAL -79.96209824445856 COL address VAL nan COL postalCode VAL nan '\n",
      "Place 2: 'COL name VAL Panther Hollow Lot COL latitude VAL 40.4404019017384 COL longitude VAL -79.95040009542119 COL address VAL 8 Boundary Street COL postalCode VAL 15260 '\n",
      "\n",
      "Answer: \n",
      "testing completed........\n",
      "['datasets', 'osm_fsq_plm', 'pit', '']\n",
      "{'Precision': 0.9137931034482759, 'Recall': 0.12128146453089245, 'F1 Score': 0.21414141414141413}\n",
      "{'Precision': 0.9137931034482759, 'Recall': 0.12128146453089245, 'F1 Score': 0.21414141414141413}\n",
      "{'Precision': 0.741011984021305, 'Recall': 0.741011984021305, 'F1 Score': 0.741011984021305}\n",
      "{'Precision': 0.8239325628044704, 'Recall': 0.5582933144250707, 'F1 Score': 0.5295497823995233}\n",
      "['datasets', 'osm_fsq_plm', 'sin', '']\n"
     ]
    },
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b02342b25ecc4724b505fe03c3fe846e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating valid split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5dcbaf7ddfa04046ae96c05d184da179"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating test split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "05176d579d7a47c2abb04b4f9cda59e0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully loaded dataset.......\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e1a81f8c2ff643cbad01250f20b62061"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model........\n",
      "loaded tokenizer........\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Place1: 'COL name VAL Arc at Tampines COL latitude VAL 1.3500460559015015 COL longitude VAL 103.9284656571354 COL address VAL Tampines Avenue 8 COL postalCode VAL nan '\n",
      "Place2: 'COL name VAL Blk 701 Tampines COL latitude VAL 1.3563375389869587 COL longitude VAL 103.93701273271752 COL address VAL nan COL postalCode VAL nan '<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "No<|eot_id|>\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.\n",
      "Place 1: 'COL name VAL Garden Apartments COL latitude VAL 1.3123865010572997 COL longitude VAL 103.82490180924768 COL address VAL nan COL postalCode VAL nan '\n",
      "Place 2: 'COL name VAL Le Grove Apartments COL latitude VAL 1.3133607473862063 COL longitude VAL 103.82573283698127 COL address VAL 32 Orange Grove Rd COL postalCode VAL nan '\n",
      "\n",
      "Answer: \n",
      "testing completed........\n",
      "['datasets', 'osm_fsq_plm', 'sin', '']\n",
      "{'Precision': 0.4939759036144578, 'Recall': 0.06376360808709176, 'F1 Score': 0.11294765840220387}\n",
      "{'Precision': 0.4939759036144578, 'Recall': 0.06376360808709176, 'F1 Score': 0.11294765840220386}\n",
      "{'Precision': 0.8884655351576031, 'Recall': 0.8884655351576031, 'F1 Score': 0.8884655351576031}\n",
      "{'Precision': 0.6940974229019399, 'Recall': 0.5277890346028911, 'F1 Score': 0.5267196248026543}\n",
      "['datasets', 'osm_fsq_plm', 'tor', '']\n"
     ]
    },
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9468c217dda6449d851019455eb1798b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating valid split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "caf6c8e071af41dab5af2c47435eae14"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating test split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "051cc0a79c6b401287afabc54e78c531"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully loaded dataset.......\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b448c1fc9183479fb0f6d45b0479b199"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model........\n",
      "loaded tokenizer........\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Place1: 'COL name VAL High Park Club COL latitude VAL 43.642713184065045 COL longitude VAL -79.45409309915006 COL address VAL nan COL postalCode VAL nan '\n",
      "Place2: 'COL name VAL High Park Pond COL latitude VAL 43.6362311235597 COL longitude VAL -79.44104765424458 COL address VAL nan COL postalCode VAL nan '<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "No<|eot_id|>\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.\n",
      "Place 1: 'COL name VAL Bloor Collegiate Institute COL latitude VAL 43.65892111180895 COL longitude VAL -79.43699172520552 COL address VAL Bloor Street West, 1141 COL postalCode VAL M6H 1M9 '\n",
      "Place 2: 'COL name VAL Harbord Collegiate Institute COL latitude VAL 43.661708714364735 COL longitude VAL -79.41400876604314 COL address VAL 286 Harbord St., at Euclid Ave. COL postalCode VAL M6G 1G5 '\n",
      "\n",
      "Answer: \n",
      "testing completed........\n",
      "['datasets', 'osm_fsq_plm', 'tor', '']\n",
      "{'Precision': 0.9047619047619048, 'Recall': 0.04884318766066838, 'F1 Score': 0.09268292682926828}\n",
      "{'Precision': 0.9047619047619048, 'Recall': 0.04884318766066838, 'F1 Score': 0.09268292682926829}\n",
      "{'Precision': 0.7917521925732413, 'Recall': 0.7917521925732413, 'F1 Score': 0.7917521925732413}\n",
      "{'Precision': 0.8475848798733996, 'Recall': 0.5237059449753724, 'F1 Score': 0.4875303335664048}\n",
      "['datasets', 'osm_yelp_plm', 'edi', '']\n"
     ]
    },
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "70b8a559e78342b2bcc25ee24678f380"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating valid split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5caee72704064e68804d5d96460b0ade"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating test split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "21dd5d0426384c24bc07aab705bc09fd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully loaded dataset.......\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2ddca118fdad492dacaa0468947e1193"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model........\n",
      "loaded tokenizer........\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Place1: 'COL name VAL Box Office COL latitude VAL 55.9570681 COL longitude VAL -3.1849395 COL address VAL Greenside Place, 19 COL postalCode VAL EH1 3AA '\n",
      "Place2: 'COL name VAL The Post Office COL latitude VAL 55.9532177589 COL longitude VAL -3.2007533409 COL address VAL 40 Frederick Street COL postalCode VAL EH2 3 '<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "No<|eot_id|>\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.\n",
      "Place 1: 'COL name VAL The Square COL latitude VAL 55.956014 COL longitude VAL -3.1919268 COL address VAL North St Andrew Street, 17 COL postalCode VAL nan '\n",
      "Place 2: 'COL name VAL The Cupboard COL latitude VAL 55.9495698 COL longitude VAL -3.211894 COL address VAL 10 William Street COL postalCode VAL EH3 7NH '\n",
      "\n",
      "Answer: \n",
      "testing completed........\n",
      "['datasets', 'osm_yelp_plm', 'edi', '']\n",
      "{'Precision': 1.0, 'Recall': 0.1240981240981241, 'F1 Score': 0.220795892169448}\n",
      "{'Precision': 1.0, 'Recall': 0.1240981240981241, 'F1 Score': 0.220795892169448}\n",
      "{'Precision': 0.8920120974915495, 'Recall': 0.8920120974915495, 'F1 Score': 0.8920120974915495}\n",
      "{'Precision': 0.94516711833785, 'Recall': 0.562049062049062, 'F1 Score': 0.5813909691182708}\n",
      "['datasets', 'osm_yelp_plm', 'pit', '']\n"
     ]
    },
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "437170fb28f14e71a644195efaba319b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating valid split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a0179565a58b4bbdb85e0ffaa8045b22"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating test split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a2f397ddeceb43f9bd342f5bff3df333"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully loaded dataset.......\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "72dfdc19d696413fbbf713f5a99466ba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model........\n",
      "loaded tokenizer........\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Place1: 'COL name VAL Ross Park Mall COL latitude VAL 40.546375 COL longitude VAL -80.0049185 COL address VAL   COL postalCode VAL   '\n",
      "Place2: 'COL name VAL Tesla - Ross Park Mall COL latitude VAL 40.5389691 COL longitude VAL -80.0077114 COL address VAL 1000 Ross Park Mall Dr COL postalCode VAL 15237.0 '<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "No<|eot_id|>\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.\n",
      "Place 1: 'COL name VAL Cafe Du Jour COL latitude VAL 40.42908668865597 COL longitude VAL -79.98694189998093 COL address VAL East Carson Street, 1107 COL postalCode VAL 15203 '\n",
      "Place 2: 'COL name VAL Cafe Euro COL latitude VAL 40.441532 COL longitude VAL -79.995221 COL address VAL 600 Grant St COL postalCode VAL 15219.0 '\n",
      "\n",
      "Answer: \n",
      "testing completed........\n",
      "['datasets', 'osm_yelp_plm', 'pit', '']\n",
      "{'Precision': 0.9508196721311475, 'Recall': 0.11909650924024641, 'F1 Score': 0.2116788321167883}\n",
      "{'Precision': 0.9508196721311475, 'Recall': 0.11909650924024641, 'F1 Score': 0.2116788321167883}\n",
      "{'Precision': 0.71875, 'Recall': 0.71875, 'F1 Score': 0.71875}\n",
      "{'Precision': 0.8299861072520145, 'Recall': 0.5581183213503425, 'F1 Score': 0.520260969148727}\n",
      "['datasets', 'osm_yelp_plm', 'sin', '']\n"
     ]
    },
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3414f39228924ec9830f208cf1932739"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating valid split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "83b4192362c2446c9b9606a079898e99"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating test split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e8d434082bda4f148ea59e7be81b3530"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully loaded dataset.......\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0a6218ed092e481c8d75369967c03bd6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model........\n",
      "loaded tokenizer........\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Place1: 'COL name VAL ZamZam Singapore COL latitude VAL 1.3019268 COL longitude VAL 103.857911 COL address VAL nan COL postalCode VAL nan '\n",
      "Place2: 'COL name VAL NotarySingapore COL latitude VAL 1.3062907 COL longitude VAL 103.853317 COL address VAL 51A Upper Weld Rd COL postalCode VAL 207408.0 '<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "No<|eot_id|>\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.\n",
      "Place 1: 'COL name VAL Forum Restaurant COL latitude VAL 1.2866651 COL longitude VAL 103.8494922 COL address VAL nan COL postalCode VAL nan '\n",
      "Place 2: 'COL name VAL Shin Yeh Restaurant COL latitude VAL 1.29153954075445 COL longitude VAL 103.844539672136 COL address VAL 177 River Valley Road, #02-19, Liang Court COL postalCode VAL 179030.0 '\n",
      "\n",
      "Answer: \n",
      "testing completed........\n",
      "['datasets', 'osm_yelp_plm', 'sin', '']\n",
      "{'Precision': 0.65, 'Recall': 0.044167610419026046, 'F1 Score': 0.08271474019088017}\n",
      "{'Precision': 0.65, 'Recall': 0.044167610419026046, 'F1 Score': 0.08271474019088017}\n",
      "{'Precision': 0.8664711330657611, 'Recall': 0.8664711330657611, 'F1 Score': 0.8664711330657611}\n",
      "{'Precision': 0.7592474291056404, 'Recall': 0.5202071296062959, 'F1 Score': 0.505354706314536}\n",
      "['datasets', 'osm_yelp_plm', 'tor', '']\n"
     ]
    },
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0bef4f8d75c0468985be4315c631d6b3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating valid split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "22c83edff16e4cd9b6d4027da3e911ba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating test split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "13e77dd336454d789945ec2c484d7ef8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully loaded dataset.......\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4f4125f7ddd042bb9b64306506010a5b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model........\n",
      "loaded tokenizer........\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Place1: 'COL name VAL Ossington Bus Terminal COL latitude VAL 43.66233675086265 COL longitude VAL -79.4264579363051 COL address VAL nan COL postalCode VAL nan '\n",
      "Place2: 'COL name VAL Ossington Tire COL latitude VAL 43.6475 COL longitude VAL -79.420073 COL address VAL 146 Ossington Avenue COL postalCode VAL M6J 2Z5 '<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "No<|eot_id|>\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.\n",
      "Place 1: 'COL name VAL Mister Tasty's Restaurant COL latitude VAL 43.6887671 COL longitude VAL -79.2969779 COL address VAL nan COL postalCode VAL nan '\n",
      "Place 2: 'COL name VAL Sandy's Restaurant COL latitude VAL 43.6855652 COL longitude VAL -79.3122921 COL address VAL 2093 Danforth Ave COL postalCode VAL M4C 1K1 '\n",
      "\n",
      "Answer: \n",
      "testing completed........\n",
      "['datasets', 'osm_yelp_plm', 'tor', '']\n",
      "{'Precision': 0.9664804469273743, 'Recall': 0.10626535626535627, 'F1 Score': 0.1914775871610404}\n",
      "{'Precision': 0.9664804469273743, 'Recall': 0.10626535626535627, 'F1 Score': 0.1914775871610404}\n",
      "{'Precision': 0.8258848766535574, 'Recall': 0.8258848766535574, 'F1 Score': 0.8258848766535574}\n",
      "{'Precision': 0.8946503549785434, 'Recall': 0.5526890880099515, 'F1 Score': 0.5469574914102364}\n",
      "['datasets', 'acheson_plm', 'swiss', '']\n"
     ]
    },
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c2ce1d548b5148cc83ed4170735e9a61"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating valid split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "77264467b6c84e09b10c5711fa6f2f5e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating test split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e46d90b5cf994f4da588cc47f1c04123"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully loaded dataset.......\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b6f2bae09cb74dc6b9691dbfa0a32c1d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model........\n",
      "loaded tokenizer........\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Place1: 'COL name VAL Gross Chärpf COL type VAL mountain COL latitude VAL 46.91674 COL longitude VAL 9.09322 '\n",
      "Place2: 'COL name VAL Chalchstöckli COL type VAL Gipfel COL latitude VAL 46.903126460802675 COL longitude VAL 9.06691611355023 '<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "No<|eot_id|>\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.\n",
      "Place 1: 'COL name VAL Piz Mezdi COL type VAL peak COL latitude VAL 46.47009 COL longitude VAL 9.86314 '\n",
      "Place 2: 'COL name VAL La Crasta COL type VAL Gipfel COL latitude VAL 46.49094755900441 COL longitude VAL 9.875518177680942 '\n",
      "\n",
      "Answer: \n",
      "testing completed........\n",
      "['datasets', 'acheson_plm', 'swiss', '']\n",
      "{'Precision': 0.8, 'Recall': 0.41025641025641024, 'F1 Score': 0.5423728813559321}\n",
      "{'Precision': 0.8, 'Recall': 0.41025641025641024, 'F1 Score': 0.5423728813559322}\n",
      "{'Precision': 0.9785373608903021, 'Recall': 0.9785373608903021, 'F1 Score': 0.9785373608903021}\n",
      "{'Precision': 0.8907108239095316, 'Recall': 0.7034875160387876, 'F1 Score': 0.7656919351834606}\n"
     ]
    }
   ],
   "source": [
    "logging.set_verbosity_error()\n",
    "for dataset_folder in dataset_folder_path:\n",
    " \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    print(dataset_folder.split(\"\\\\\"))\n",
    "    dataset_output_path_1, dataset_output_path_2 = dataset_folder.split(\"\\\\\")[-3], dataset_folder.split(\"\\\\\")[-2]\n",
    "        \n",
    "    dataset = load_dataset(\n",
    "        \"json\",\n",
    "        data_files={\"train\": dataset_folder+\"train.json\", \"valid\": dataset_folder+\"valid.json\", \"test\": dataset_folder+\"test.json\"},\n",
    "    )\n",
    "    print(\"successfully loaded dataset.......\")\n",
    "    \n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        trust_remote_code=True,\n",
    "        config=model_config,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map='auto',\n",
    "        token=True\n",
    "    )\n",
    "    \n",
    "    print(\"loaded model........\")\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        token=True\n",
    "    )\n",
    "    \n",
    "    print(\"loaded tokenizer........\")\n",
    "    PAD_TOKEN = tokenizer.eos_token\n",
    "    tokenizer.add_special_tokens({\"pad_token\": PAD_TOKEN})\n",
    "    tokenizer.padding_side = \"right\"\n",
    "    \n",
    "    \n",
    "    # model = prepare_model_for_kbit_training(model)\n",
    "    # model = get_peft_model(model, lora_config)\n",
    "    \n",
    "    print(dataset['train'][0]['text'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # OUTPUT_DIR = \"experiments\\\\\"+ dataset_output_path_1 +\"\\\\\"+ dataset_output_path_2+\"\\\\\"\n",
    "    # \n",
    "    # os.makedirs(os.path.dirname(OUTPUT_DIR), exist_ok=True)\n",
    "    # \n",
    "    # sft_config = SFTConfig(\n",
    "    #     output_dir=OUTPUT_DIR,\n",
    "    #     dataset_text_field=\"text\",\n",
    "    #     max_seq_length=256,\n",
    "    #     num_train_epochs=2,\n",
    "    #     per_device_train_batch_size=6,\n",
    "    #     per_device_eval_batch_size=4,\n",
    "    #     gradient_accumulation_steps=4,\n",
    "    #     # optim=\"paged_adamw_8bit\",\n",
    "    #     # eval_strategy=\"steps\",\n",
    "    #     # eval_steps=0,\n",
    "    #     #save_steps=0.2,\n",
    "    #     logging_steps=10,\n",
    "    #     learning_rate=1e-4,\n",
    "    #     # fp16=True,  # or \n",
    "    #     bf16=True,\n",
    "    #     save_strategy=\"steps\",\n",
    "    #     warmup_ratio=0.1,\n",
    "    #     save_total_limit=0,\n",
    "    #     lr_scheduler_type=\"constant\",\n",
    "    #     # report_to=\"tensorboard\",\n",
    "    #     save_safetensors=True,\n",
    "    #     dataset_kwargs={\n",
    "    #         \"add_special_tokens\": False,  \n",
    "    #         \"append_concat_token\": False, \n",
    "    #     },\n",
    "    # )\n",
    "    # \n",
    "    # trainer = SFTTrainer(\n",
    "    #     model=model,\n",
    "    #     args=sft_config,\n",
    "    #     train_dataset=dataset[\"train\"],\n",
    "    #     eval_dataset=dataset[\"valid\"],\n",
    "    #     tokenizer=tokenizer,\n",
    "    # )\n",
    "    # \n",
    "    # print(\"starting training...........\")\n",
    "    # \n",
    "    # \n",
    "    # start_time_train = time.time()\n",
    "    # trainer.train()\n",
    "    # end_time_train = time.time()\n",
    "    # elapsed_time_train = end_time_train - start_time_train\n",
    "    # \n",
    "    # print('training completed....')\n",
    "    # \n",
    "    # trainer.save_model(OUTPUT_DIR)\n",
    "    # \n",
    "    # print('model saved .........')\n",
    "    \n",
    "    test_prompts = [format_test(x, \"zero\") for x in dataset['test']]\n",
    "    \n",
    "    print(test_prompts[0])\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    batch_size=10\n",
    "    results=[]\n",
    "    start_time_test = time.time()\n",
    "    with torch.no_grad():\n",
    "        # for i in range(0, len(test_prompts), batch_size):\n",
    "        for prompt in test_prompts:\n",
    "                inputs = tokenizer(prompt, return_tensors=\"pt\").to(device='cuda')\n",
    "                # outputs = model.pipeline(inputs.input_ids)\n",
    "                # batch = test_prompts[i:i + batch_size]\n",
    "                # inputs = tokenizer(batch, return_tensors=\"pt\", truncation=True,padding=True).to(device='cuda')\n",
    "                outputs = model.generate(\n",
    "                    inputs.input_ids, \n",
    "                    max_length=256,  # Maximum length of the generated text\n",
    "                    max_new_tokens= 1,\n",
    "                    num_return_sequences=1,  # Number of sequences to generate\n",
    "                    no_repeat_ngram_size=2,  # Avoid repeating phrases\n",
    "                    temperature=0.01,  # Controls randomness; lower is less random\n",
    "                    top_k=50,  # Top-k sampling\n",
    "                )\n",
    "                prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "                # prediction = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "                # prediction = tokenizer.decode(outputs[:, inputs.shape[1]:])\n",
    "                # results.extend([x.strip() for x in prediction])\n",
    "                results.append(prediction.strip())\n",
    "\n",
    "    end_time_test = time.time()\n",
    "    elapsed_time_test = end_time_test - start_time_test\n",
    "    \n",
    "    print(\"testing completed........\")\n",
    "    \n",
    "    predictions = [x.split(\" \")[-1].strip() for x in results]\n",
    "    # predictions = [x.split(\"\\n\")[-1].strip() for x in results]\n",
    "    \n",
    "    predictions = [1 if label == \"Yes\" else 0 if label == \"No\" else 2 for label in predictions]\n",
    "    # print(predictions)\n",
    "    labels = [1 if label == \"Yes\" else 0 for label in dataset['test']['answer']]\n",
    "    # print(labels)\n",
    "    print(dataset_folder.split(\"\\\\\"))\n",
    "    \n",
    "    try:\n",
    "        my_mets = calc_mets_my(predictions, labels)\n",
    "        print(my_mets)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('my calc failed')\n",
    "        my_mets = 'my calc failed'\n",
    "    \n",
    "    try:\n",
    "        bin_mets = calculate_metrics(predictions, labels, 'binary')\n",
    "        print(bin_mets)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('binary failed')\n",
    "        bin_mets = 'binary failed'\n",
    "        \n",
    "    try:\n",
    "        micro_mets = calculate_metrics(predictions, labels, 'micro')\n",
    "        print(micro_mets)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('micro failed')\n",
    "        micro_mets = 'micro failed'\n",
    "        \n",
    "    try:\n",
    "        macro_mets = calculate_metrics(predictions, labels, 'macro')\n",
    "        print(macro_mets)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('macro failed')\n",
    "        macro_mets = 'macro failed'\n",
    "        \n",
    "    with open(\"zero_plm_results.txt\", \"a\", encoding='utf-8') as f:\n",
    "        f.write(str(dataset_output_path_1))\n",
    "        f.write(str(dataset_output_path_2))\n",
    "        f.write('\\n')\n",
    "        f.write(str(dataset['train'][0]['text']))\n",
    "        f.write('\\n')\n",
    "        f.write(str(results[0]))\n",
    "        f.write('\\n')\n",
    "        f.write('\\n')\n",
    "        f.write(str(my_mets))\n",
    "        f.write('\\n')\n",
    "        f.write(str(bin_mets))\n",
    "        f.write('\\n')\n",
    "        f.write(str(micro_mets))\n",
    "        f.write('\\n')\n",
    "        f.write(str(macro_mets))\n",
    "        f.write('\\n')\n",
    "        # f.write(str(elapsed_time_train))\n",
    "        f.write('\\n')\n",
    "        f.write(str(elapsed_time_test))\n",
    "        f.write('\\n')\n",
    "        f.write('\\n')\n",
    "        f.write('********************************')\n",
    "        f.write('\\n')\n",
    "        f.write('\\n')\n",
    "        \n",
    "    \n",
    "    del model  # Delete the model instance\n",
    "    del tokenizer\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-09T02:10:29.504114Z",
     "start_time": "2025-01-08T23:52:18.220815700Z"
    }
   },
   "id": "aa40a52dc11414ed",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataset_folder_path = ['datasets\\\\gtminer_plm\\\\mel\\\\', 'datasets\\gtminer_plm\\\\sea\\\\', 'datasets\\gtminer_plm\\\\sin\\\\', 'datasets\\\\gtminer_plm\\\\tor\\\\']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-09T02:10:29.553102400Z",
     "start_time": "2025-01-09T02:10:29.497106500Z"
    }
   },
   "id": "29b958deba50ee44",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['datasets', 'gtminer_plm', 'mel', '']\n"
     ]
    },
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "48afc27593c64c6cb692194af984d523"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating valid split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "86fc4a31e1ca47dbb9a6be6e861a3ee6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating test split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dd88c97bb703436598e14c371c73d4c1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully loaded dataset.......\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "067813969c9b4f988bc34c31686a1784"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model........\n",
      "loaded tokenizer........\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Two place descriptions are provided. Answer with 'same_as' if the first place is the same as the second place. Answer with 'part_of' if the first place is a part of the second place and is located inside the second place. Answer with 'serves' if the first place provides a service to the second place in terms of human mobility, assistance, etc. Answer with 'unknown' if the two places show none of these relations.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Place 1: 'COL name VAL Department of Environment, Land, Water and Planning COL type VAL office COL address VAL 8 Nicholson Street 3002 COL latitude VAL -37.8083722 COL longitude VAL 144.9734604 '\n",
      "Place 2: 'COL name VAL Hotel Ovolo COL type VAL hotel COL address VAL 19 Little Bourke Street 3000 COL latitude VAL -37.8107508 COL longitude VAL 144.9719983 '\n",
      "Answer only with: same_as, part_of, serves, unknown<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "unknown<|eot_id|>\n",
      "testing completed........\n",
      "['datasets', 'gtminer_plm', 'mel', '']\n",
      "P: 0.4533  |  R: 0.7398  |  F1: 0.5621\n",
      "{'precision': 0.4533042053522665, 'recall': 0.7397504456327986, 'f1': 0.5621401964104301}\n",
      "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "binary failed\n",
      "{'Precision': 0.4551386623164764, 'Recall': 0.4551386623164764, 'F1 Score': 0.4551386623164764}\n",
      "{'Precision': 0.5225, 'Recall': 0.2835906340736077, 'F1 Score': 0.21398691256352936}\n",
      "['datasets', 'gtminer_plm', 'sea', '']\n"
     ]
    },
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "807dd74e7d3047e7981d0ad29f3e52ff"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating valid split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9aa4391405a44a35b95a0913da02226d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating test split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2bdde17e52924c34866102cee4f066c9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully loaded dataset.......\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5632a7e0713f4e188b3bd16ec22e1033"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model........\n",
      "loaded tokenizer........\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Two place descriptions are provided. Answer with 'same_as' if the first place is the same as the second place. Answer with 'part_of' if the first place is a part of the second place and is located inside the second place. Answer with 'serves' if the first place provides a service to the second place in terms of human mobility, assistance, etc. Answer with 'unknown' if the two places show none of these relations.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Place 1: 'COL name VAL The Grilled Cheese Experience COL type VAL cafe COL address VAL 909 Pike Street 98101 COL latitude VAL 47.6123242 COL longitude VAL -122.3309093 '\n",
      "Place 2: 'COL name VAL Washington State Convention Center COL type VAL attraction COL address VAL 800 Convention Place 98101 COL latitude VAL 47.6117274 COL longitude VAL -122.3316528 '\n",
      "Answer only with: same_as, part_of, serves, unknown<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "part_of<|eot_id|>\n",
      "testing completed........\n",
      "['datasets', 'gtminer_plm', 'sea', '']\n",
      "P: 0.2899  |  R: 0.6962  |  F1: 0.4093\n",
      "{'precision': 0.2898828541001065, 'recall': 0.6961636828644501, 'f1': 0.4093233082706767}\n",
      "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "binary failed\n",
      "{'Precision': 0.2972403623341057, 'Recall': 0.2972403623341057, 'F1 Score': 0.2972403623341057}\n",
      "{'Precision': 0.521038890983744, 'Recall': 0.3211689533341233, 'F1 Score': 0.2221926608184136}\n",
      "['datasets', 'gtminer_plm', 'sin', '']\n"
     ]
    },
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "05728558075b4703ad64af59b0ea055b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating valid split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "77d99bdd03c24bd9a362c79863ede856"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating test split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bfe0fd5100624a6b8671197c4812dd63"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully loaded dataset.......\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "39227e1a53b7425e99835bcfc7d41001"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model........\n",
      "loaded tokenizer........\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Two place descriptions are provided. Answer with 'same_as' if the first place is the same as the second place. Answer with 'part_of' if the first place is a part of the second place and is located inside the second place. Answer with 'serves' if the first place provides a service to the second place in terms of human mobility, assistance, etc. Answer with 'unknown' if the two places show none of these relations.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Place 1: 'COL name VAL City Square Post Office COL type VAL post_office COL address VAL 180 Kitchener Road #B2-33 City Square 208539 COL latitude VAL 1.3109755 COL longitude VAL 103.8567196 '\n",
      "Place 2: 'COL name VAL Mustafa Centre COL type VAL Shopping Centers COL address VAL 145 Syed Alwi Road 207704 COL latitude VAL 1.3101243 COL longitude VAL 103.8553164 '\n",
      "Answer only with: same_as, part_of, serves, unknown<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "unknown<|eot_id|>\n",
      "testing completed........\n",
      "['datasets', 'gtminer_plm', 'sin', '']\n",
      "P: 0.3317  |  R: 0.6598  |  F1: 0.4414\n",
      "{'precision': 0.3316629302386918, 'recall': 0.6597586568730325, 'f1': 0.44142167617376044}\n",
      "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "binary failed\n",
      "{'Precision': 0.34742740703005603, 'Recall': 0.34742740703005603, 'F1 Score': 0.34742740703005603}\n",
      "{'Precision': 0.3800791940791522, 'Recall': 0.31811181452421367, 'F1 Score': 0.23024974461725892}\n",
      "['datasets', 'gtminer_plm', 'tor', '']\n"
     ]
    },
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "40fd07007ca94e5c8d2462f3010e64ef"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating valid split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b84f79db9fde4d10bf4df50d17a19d8e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating test split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1c7cc5578bbc46c5a4e12341afd663fa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully loaded dataset.......\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b3463b0246584f03a73cf5d691b96e21"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model........\n",
      "loaded tokenizer........\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Two place descriptions are provided. Answer with 'same_as' if the first place is the same as the second place. Answer with 'part_of' if the first place is a part of the second place and is located inside the second place. Answer with 'serves' if the first place provides a service to the second place in terms of human mobility, assistance, etc. Answer with 'unknown' if the two places show none of these relations.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Place 1: 'COL name VAL First Copy COL type VAL copyshop COL address VAL 61 College Street COL latitude VAL 43.6605215 COL longitude VAL -79.386228 '\n",
      "Place 2: 'COL name VAL Medical Sciences Building COL type VAL Colleges & Universities; Education COL address VAL 1 King's College Cir M5S 1A8 COL latitude VAL 43.6607748 COL longitude VAL -79.3933729 '\n",
      "Answer only with: same_as, part_of, serves, unknown<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "unknown<|eot_id|>\n",
      "testing completed........\n",
      "['datasets', 'gtminer_plm', 'tor', '']\n",
      "P: 0.344  |  R: 0.7214  |  F1: 0.4659\n",
      "{'precision': 0.3440192346223202, 'recall': 0.7214285714285714, 'f1': 0.46587979921313255}\n",
      "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "binary failed\n",
      "{'Precision': 0.35522446579102135, 'Recall': 0.35522446579102135, 'F1 Score': 0.35522446579102135}\n",
      "{'Precision': 0.4195985408269891, 'Recall': 0.29651584934433334, 'F1 Score': 0.2085200195530726}\n"
     ]
    }
   ],
   "source": [
    "logging.set_verbosity_error()\n",
    "\n",
    "\n",
    "for dataset_folder in dataset_folder_path:\n",
    " \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    print(dataset_folder.split(\"\\\\\"))\n",
    "    dataset_output_path_1, dataset_output_path_2 = dataset_folder.split(\"\\\\\")[-3], dataset_folder.split(\"\\\\\")[-2]\n",
    "        \n",
    "    dataset = load_dataset(\n",
    "        \"json\",\n",
    "        data_files={\"train\": dataset_folder+\"train.json\", \"valid\": dataset_folder+\"valid.json\", \"test\": dataset_folder+\"test.json\"},\n",
    "    )\n",
    "    print(\"successfully loaded dataset.......\")\n",
    "    \n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        trust_remote_code=True,\n",
    "        config=model_config,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map='auto',\n",
    "        token=True\n",
    "    )\n",
    "    \n",
    "    print(\"loaded model........\")\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        token=True\n",
    "    )\n",
    "    \n",
    "    print(\"loaded tokenizer........\")\n",
    "    PAD_TOKEN = tokenizer.eos_token\n",
    "    tokenizer.add_special_tokens({\"pad_token\": PAD_TOKEN})\n",
    "    tokenizer.padding_side = \"right\"\n",
    "    \n",
    "    \n",
    "    # model = prepare_model_for_kbit_training(model)\n",
    "    # model = get_peft_model(model, lora_config)\n",
    "    \n",
    "    print(dataset['train'][0]['text'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # OUTPUT_DIR = \"experiments\\\\\"+ dataset_output_path_1 +\"\\\\\"+ dataset_output_path_2+\"\\\\\"\n",
    "    # \n",
    "    # os.makedirs(os.path.dirname(OUTPUT_DIR), exist_ok=True)\n",
    "    # \n",
    "    # sft_config = SFTConfig(\n",
    "    #     output_dir=OUTPUT_DIR,\n",
    "    #     dataset_text_field=\"text\",\n",
    "    #     max_seq_length=300,\n",
    "    #     num_train_epochs=2,\n",
    "    #     per_device_train_batch_size=6,\n",
    "    #     per_device_eval_batch_size=4,\n",
    "    #     gradient_accumulation_steps=4,\n",
    "    #     # optim=\"paged_adamw_8bit\",\n",
    "    #     # eval_strategy=\"steps\",\n",
    "    #     # eval_steps=0,\n",
    "    #     #save_steps=0.2,\n",
    "    #     logging_steps=10,\n",
    "    #     learning_rate=1e-4,\n",
    "    #     # fp16=True,  # or \n",
    "    #     bf16=True,\n",
    "    #     save_strategy=\"steps\",\n",
    "    #     warmup_ratio=0.1,\n",
    "    #     save_total_limit=0,\n",
    "    #     lr_scheduler_type=\"constant\",\n",
    "    #     # report_to=\"tensorboard\",\n",
    "    #     save_safetensors=True,\n",
    "    #     dataset_kwargs={\n",
    "    #         \"add_special_tokens\": False,  \n",
    "    #         \"append_concat_token\": False, \n",
    "    #     },\n",
    "    # )\n",
    "    # \n",
    "    # trainer = SFTTrainer(\n",
    "    #     model=model,\n",
    "    #     args=sft_config,\n",
    "    #     train_dataset=dataset[\"train\"],\n",
    "    #     eval_dataset=dataset[\"valid\"],\n",
    "    #     tokenizer=tokenizer,\n",
    "    # )\n",
    "    # \n",
    "    # print(\"starting training...........\")\n",
    "    # \n",
    "    # \n",
    "    # \n",
    "    # start_time_train = time.time()\n",
    "    # trainer.train()\n",
    "    # end_time_train = time.time()\n",
    "    # elapsed_time_train = end_time_train - start_time_train\n",
    "    # \n",
    "    # print('training completed....')\n",
    "    # \n",
    "    # trainer.save_model(OUTPUT_DIR)\n",
    "    # \n",
    "    # print('model saved .........')\n",
    "    \n",
    "    # if dataset_output_path_1 ==\"gtminer\":\n",
    "    test_prompts = [format_test_gtminer(x, \"zero\") for x in dataset['test']]\n",
    "    # elif dataset_output_path_1 ==\"gtminer3\":\n",
    "    #     test_prompts = [format_test_gtminer3(x) for x in dataset['test']]\n",
    "    \n",
    "    results=[]\n",
    "    start_time_test = time.time()  \n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for prompt in test_prompts:\n",
    "                inputs = tokenizer(prompt, return_tensors=\"pt\").to(device='cuda')\n",
    "                # outputs = model.pipeline(inputs.input_ids)\n",
    "                outputs = model.generate(\n",
    "                    inputs.input_ids, \n",
    "                    max_length=300,  # Maximum length of the generated text\n",
    "                    max_new_tokens= 2,\n",
    "                    num_return_sequences=1,  # Number of sequences to generate\n",
    "                    no_repeat_ngram_size=2,  # Avoid repeating phrases\n",
    "                    temperature=0.01,  # Controls randomness; lower is less random\n",
    "                    top_k=50,  # Top-k sampling\n",
    "                )\n",
    "                prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "                # prediction = tokenizer.decode(outputs[:, inputs.shape[1]:])\n",
    "                results.append(prediction.strip())\n",
    "    \n",
    "    end_time_test = time.time()\n",
    "    elapsed_time_test = end_time_test - start_time_test\n",
    "    \n",
    "    print(\"testing completed........\")\n",
    "    # print(results)\n",
    "    predictions = [x.split(\":\")[-1].strip() for x in results]\n",
    "    # predictions = [x.split(\"\\n\")[-1].strip() for x in results]\n",
    "    \n",
    "    predictions = [1 if label in [\"same_as\", \"same\", \"same-as\"] else 2 if label in [\"part_of\", \"part-of\", \"partof\"] else 3 if label in [\"serves\", \"served\"] else 0 if label in [\"unknown\"] else 4 for label in predictions]\n",
    "    # print(predictions)\n",
    "    labels = [1 if label == \"same_as\" else 2 if label == \"part_of\" else 3 if label == \"serves\" else 0 if label == \"unknown\" else 5 for label in dataset['test']['answer']]\n",
    "    # print(labels)\n",
    "    print(dataset_folder.split(\"\\\\\"))\n",
    "    \n",
    "    try:\n",
    "        my_mets = calculate_metrics2(predictions, labels)\n",
    "        print(my_mets)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('my calc failed')\n",
    "        my_mets = 'my calc failed'\n",
    "    \n",
    "    try:\n",
    "        bin_mets = calculate_metrics(predictions, labels, 'binary')\n",
    "        print(bin_mets)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('binary failed')\n",
    "        bin_mets = 'binary failed'\n",
    "        \n",
    "    try:\n",
    "        micro_mets = calculate_metrics(predictions, labels, 'micro')\n",
    "        print(micro_mets)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('micro failed')\n",
    "        micro_mets = 'micro failed'\n",
    "        \n",
    "    try:\n",
    "        macro_mets = calculate_metrics(predictions, labels, 'macro')\n",
    "        print(macro_mets)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('macro failed')\n",
    "        macro_mets = 'macro failed'\n",
    "        \n",
    "    with open(\"zero_gtminer_plm_results.txt\", \"a\", encoding='utf-8') as f:\n",
    "        f.write(str(dataset_output_path_1))\n",
    "        f.write(str(dataset_output_path_2))\n",
    "        f.write('\\n')\n",
    "        f.write(str(dataset['train'][0]['text']))\n",
    "        f.write('\\n')\n",
    "        f.write(str(results[0]))\n",
    "        f.write('\\n')\n",
    "        f.write('\\n')\n",
    "        f.write(str(my_mets))\n",
    "        f.write('\\n')\n",
    "        f.write(str(bin_mets))\n",
    "        f.write('\\n')\n",
    "        f.write(str(micro_mets))\n",
    "        f.write('\\n')\n",
    "        f.write(str(macro_mets))\n",
    "        f.write('\\n')\n",
    "        # f.write(str(elapsed_time_train))\n",
    "        f.write('\\n')\n",
    "        f.write(str(elapsed_time_test))\n",
    "        f.write('\\n')\n",
    "        f.write('\\n')\n",
    "        f.write('********************************')\n",
    "        f.write('\\n')\n",
    "        f.write('\\n')\n",
    "    \n",
    "    del model  # Delete the model instance\n",
    "    del tokenizer\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-09T03:34:40.010831800Z",
     "start_time": "2025-01-09T02:10:29.560105600Z"
    }
   },
   "id": "3c388bd36b26fd96",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "MODEL_NAME = 'meta-llama/Meta-Llama-3-8B-Instruct'\n",
    "tokenizer = AutoTokenizer.from_pretrained('experiments/my_data/auck')\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "model = PeftModel.from_pretrained(model, 'experiments/my_data/auck')\n",
    "model = model.merge_and_unload()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cec7882aeabb40bd",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
