{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-04T01:29:05.135481200Z",
     "start_time": "2025-02-04T01:29:05.120481600Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import transformers\n",
    "import pandas as pd\n",
    "from textwrap import dedent\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "MODEL_NAME = 'meta-llama/Meta-Llama-3-8B-Instruct'\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T01:29:05.434479600Z",
     "start_time": "2025-02-04T01:29:05.421480700Z"
    }
   },
   "id": "174a428754203b8d",
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    token=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T01:29:09.427989100Z",
     "start_time": "2025-02-04T01:29:06.622472400Z"
    }
   },
   "id": "6b10ae2259f0090a",
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "PAD_TOKEN = tokenizer.eos_token\n",
    "tokenizer.add_special_tokens({\"pad_token\": PAD_TOKEN})\n",
    "tokenizer.padding_side = \"right\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T01:29:09.437989700Z",
     "start_time": "2025-02-04T01:29:09.427989100Z"
    }
   },
   "id": "98be22afca0f5525",
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Calculate the great-circle distance between two points on the Earth's surface.\n",
    "\n",
    "    Parameters:\n",
    "    lat1, lon1: Latitude and Longitude of the first point in decimal degrees.\n",
    "    lat2, lon2: Latitude and Longitude of the second point in decimal degrees.\n",
    "\n",
    "    Returns:\n",
    "    Distance in kilometers.\n",
    "    \"\"\"\n",
    "    # Radius of the Earth in kilometers\n",
    "    R = 6371.0\n",
    "\n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lat1_rad = math.radians(lat1)\n",
    "    lon1_rad = math.radians(lon1)\n",
    "    lat2_rad = math.radians(lat2)\n",
    "    lon2_rad = math.radians(lon2)\n",
    "\n",
    "    # Differences in coordinates\n",
    "    dlat = lat2_rad - lat1_rad\n",
    "    dlon = lon2_rad - lon1_rad\n",
    "\n",
    "    # Haversine formula\n",
    "    a = math.sin(dlat / 2)**2 + math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(dlon / 2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "\n",
    "    # Distance\n",
    "    distance = R * c\n",
    "    return f\"{distance:.2f}km\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T01:29:10.000986400Z",
     "start_time": "2025-02-04T01:29:09.984985200Z"
    }
   },
   "id": "61e06f0a7b42dcdd",
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_lat_long(entity):\n",
    "\n",
    "    words = entity.lower().split()\n",
    "    for i,word in enumerate(words):\n",
    "        if words[i-2] == 'latitude' and words[i-1] == 'val':\n",
    "          latitude = float(word)\n",
    "          longitude = float(words[i+4])\n",
    "    return  latitude, longitude"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T01:29:10.972509900Z",
     "start_time": "2025-02-04T01:29:10.925510800Z"
    }
   },
   "id": "41af39b48cd92ad3",
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def parse_file(file_path):\n",
    "    \"\"\"\n",
    "    Parses the input file and extracts entity pairs and labels.\n",
    "    :param file_path: Path to the input text file.\n",
    "    :return: A list of tuples (entity_1, entity_2, label).\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    labels=[]\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            parts = line.strip().split(\"\\t\")\n",
    "            ent_1_lat, ent_1_lon = get_lat_long(parts[0])\n",
    "            entity_1 = parts[0].replace(\"COL \", \"\").replace(\"[VAL] \", \"\").replace(\"VAL \", \"\").replace(\"name \", \"\").replace(\"type \", \"\").replace(\"latitude \", \"\").replace(\"longitude \", \"\").replace(\"postalCode \", \"\").replace(\"address \", \"\").strip()\n",
    "            ent_2_lat, ent_2_lon = get_lat_long(parts[1])\n",
    "            entity_2 = parts[1].replace(\"COL \", \"\").replace(\"[VAL] \", \"\").replace(\"VAL \", \"\").replace(\"name \", \"\").replace(\"type \", \"\").replace(\"latitude \", \"\").replace(\"longitude \", \"\").replace(\"postalCode \", \"\").replace(\"address \", \"\").strip()\n",
    "            label = parts[2]  \n",
    "            dist = haversine_distance(ent_1_lat, ent_1_lon, ent_2_lat, ent_2_lon)\n",
    "            data.append((entity_1, entity_2, dist))\n",
    "            labels.append(label)\n",
    "    return data, labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T01:29:11.007509100Z",
     "start_time": "2025-02-04T01:29:10.985513100Z"
    }
   },
   "id": "5fbdc8308a5b6d4e",
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def parse_file_att_val(file_path):\n",
    "    \"\"\"\n",
    "    Parses the input file and extracts entity pairs and labels.\n",
    "    :param file_path: Path to the input text file.\n",
    "    :return: A list of tuples (entity_1, entity_2, label).\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    labels=[]\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            parts = line.strip().split(\"\\t\")\n",
    "            ent_1_lat, ent_1_lon = get_lat_long(parts[0])\n",
    "            entity_1 = parts[0].replace(\"COL \", \"\").replace(\"[VAL] \", \"\").replace(\"VAL \", \"\").replace(\"name \", \"name: \").replace(\"type \", \"type: \").replace(\"latitude \", \"latitude: \").replace(\"longitude \", \"longitude: \").replace(\"postalCode \", \"postalCode: \").replace(\"address \", \"address: \").strip()\n",
    "            ent_2_lat, ent_2_lon = get_lat_long(parts[1])\n",
    "            entity_2 = parts[1].replace(\"COL \", \"\").replace(\"[VAL] \", \"\").replace(\"VAL \", \"\").replace(\"name \", \"name: \").replace(\"type \", \"type: \").replace(\"latitude \", \"latitude: \").replace(\"longitude \", \"longitude: \").replace(\"postalCode \", \"postalCode: \").replace(\"address \", \"address: \").strip()\n",
    "            label = parts[2] \n",
    "            dist = haversine_distance(ent_1_lat, ent_1_lon, ent_2_lat, ent_2_lon)\n",
    "            data.append((entity_1, entity_2, dist))\n",
    "            labels.append(label)\n",
    "    return data, labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T01:29:11.170508900Z",
     "start_time": "2025-02-04T01:29:11.151509Z"
    }
   },
   "id": "85e1e030396919b8",
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def parse_file_plm(file_path):\n",
    "    \"\"\"\n",
    "    Parses the input file and extracts entity pairs and labels.\n",
    "    :param file_path: Path to the input text file.\n",
    "    :return: A list of tuples (entity_1, entity_2, label).\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    labels=[]\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            parts = line.strip().split(\"\\t\")\n",
    "            ent_1_lat, ent_1_lon = get_lat_long(parts[0])\n",
    "            # entity_1 = parts[0].replace(\"COL \", \"\").replace(\"[VAL] \", \"\").replace(\"VAL \", \"\").replace(\"name \", \"name: \").replace(\"type \", \"type: \").replace(\"latitude \", \"latitude: \").replace(\"longitude \", \"longitude: \").replace(\"postalCode \", \"postalCode: \").replace(\"address \", \"address: \").strip()\n",
    "            # ent_2_lat, ent_2_lon = get_lat_long(parts[1])\n",
    "            # entity_2 = parts[1].replace(\"COL \", \"\").replace(\"[VAL] \", \"\").replace(\"VAL \", \"\").replace(\"name \", \"name: \").replace(\"type \", \"type: \").replace(\"latitude \", \"latitude: \").replace(\"longitude \", \"longitude: \").replace(\"postalCode \", \"postalCode: \").replace(\"address \", \"address: \").strip()\n",
    "            label = parts[2] \n",
    "            # dist = haversine_distance(ent_1_lat, ent_1_lon, ent_2_lat, ent_2_lon)\n",
    "            data.append((parts[0], parts[1]))\n",
    "            labels.append(label)\n",
    "    return data, labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T01:29:11.857558700Z",
     "start_time": "2025-02-04T01:29:11.843559800Z"
    }
   },
   "id": "5aa10901ebfbc51b",
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def format_example(row: dict):\n",
    "    prompt = dedent(\n",
    "        f\"\"\"\n",
    "    Place1: '{row[\"e1\"]}'\n",
    "    Place2: '{row[\"e2\"]}'\n",
    "    \"\"\"\n",
    "    )\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": row[\"answer\"]},\n",
    "    ]\n",
    "    return tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "     "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T01:29:12.486555800Z",
     "start_time": "2025-02-04T01:29:12.464555700Z"
    }
   },
   "id": "1da3714636b76d4c",
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def format_example_distance(row: dict):\n",
    "    prompt = dedent(\n",
    "        f\"\"\"\n",
    "    Place1: '{row[\"e1\"]}'\n",
    "    Place2: '{row[\"e2\"]}'\n",
    "    Distance: {row[\"distance\"]}\n",
    "    \n",
    "    \"\"\"\n",
    "    )\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Two place descriptions and the geographic distance between them is provided. Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": row[\"answer\"]},\n",
    "    ]\n",
    "    return tokenizer.apply_chat_template(messages, tokenize=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T01:29:13.564076300Z",
     "start_time": "2025-02-04T01:29:13.546075400Z"
    }
   },
   "id": "27f20eb31dd756b3",
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def format_example_gtminer(row: dict):\n",
    "    prompt = dedent(\n",
    "        f\"\"\"\n",
    "    Place 1: '{row[\"e1\"]}'\n",
    "    Place 2: '{row[\"e2\"]}'\n",
    "    Answer only with: same_as, part_of, serves, unknown\n",
    "    \"\"\"\n",
    "    )\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Two place descriptions are provided. Answer with 'same_as' if the first place is the same as the second place. Answer with 'part_of' if the first place is a part of the second place and is located inside the second place. Answer with 'serves' if the first place provides a service to the second place in terms of human mobility, assistance, etc. Answer with 'unknown' if the two places show none of these relations.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": row[\"answer\"]},\n",
    "    ]\n",
    "    return tokenizer.apply_chat_template(messages, tokenize=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T01:29:14.231599500Z",
     "start_time": "2025-02-04T01:29:14.220601500Z"
    }
   },
   "id": "3b02ba698a9b7f25",
   "execution_count": 63
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def format_example_gtminer_distance(row: dict):\n",
    "    prompt = dedent(\n",
    "        f\"\"\"\n",
    "    Place1: '{row[\"e1\"]}'\n",
    "    Place2: '{row[\"e2\"]}'\n",
    "    Distance: {row[\"distance\"]}\n",
    "    Answer only with: same_as, part_of, serves, unknown\n",
    "    \"\"\"\n",
    "    )\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Two place descriptions and the geographic distance between them are provided. Answer with 'same_as' if the first place is the same as the second place. Answer with 'part_of' if the first place is a part of the second place and is located inside the second place. Answer with 'serves' if the first place provides a service to the second place in terms of human mobility, assistance, etc. Answer with 'unknown' if the two places show none of these relations.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": row[\"answer\"]},\n",
    "    ]\n",
    "    return tokenizer.apply_chat_template(messages, tokenize=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T01:29:15.173594600Z",
     "start_time": "2025-02-04T01:29:15.163592800Z"
    }
   },
   "id": "825e89fcc1e94064",
   "execution_count": 64
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def format_example_gtminer_simple(row: dict):\n",
    "    prompt = dedent(\n",
    "        f\"\"\"\n",
    "    Place1: '{row[\"e1\"]}'\n",
    "    Place2: '{row[\"e2\"]}'\n",
    "    \"\"\"\n",
    "    )\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Two place descriptions are provided. Predict the relation between them. Answer only with ‘same_as’, ‘part_of’, ‘serves’ or ‘unknown’.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": row[\"answer\"]},\n",
    "    ]\n",
    "    return tokenizer.apply_chat_template(messages, tokenize=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T01:29:16.213586300Z",
     "start_time": "2025-02-04T01:29:16.204586800Z"
    }
   },
   "id": "668c1dda59dd5eac",
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataset_folder_paths = [\"data\\\\NZER\\\\auck\\\\\", \n",
    "                        \"data\\\\NZER\\\\hope\\\\\", \n",
    "                        \"data\\\\NZER\\\\norse\\\\\", \n",
    "                        \"data\\\\NZER\\\\north\\\\\", \n",
    "                        \"data\\\\NZER\\\\palm\\\\\", \n",
    "                        \"data\\\\GEOD_OSM_FSQ\\\\edi\\\\\", \n",
    "                        \"data\\\\GEOD_OSM_FSQ\\\\pit\\\\\", \n",
    "                        \"data\\\\GEOD_OSM_FSQ\\\\sin\\\\\",\n",
    "                        \"data\\\\GEOD_OSM_FSQ\\\\tor\\\\\",\n",
    "                        \"data\\\\GEOD_OSM_YELP\\\\edi\\\\\",\n",
    "                        \"data\\\\GEOD_OSM_YELP\\\\pit\\\\\",\n",
    "                        \"data\\\\GEOD_OSM_YELP\\\\sin\\\\\",\n",
    "                        \"data\\\\GEOD_OSM_YELP\\\\tor\\\\\",\n",
    "                        \"data\\\\SGN\\\\swiss\\\\\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T01:29:16.317585600Z",
     "start_time": "2025-02-04T01:29:16.302590800Z"
    }
   },
   "id": "8fb883140f5b4cb3",
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "prompts = ['simple', 'attribute_val', 'plm', 'attribute_value_dist']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T01:29:18.044585500Z",
     "start_time": "2025-02-04T01:29:18.037578900Z"
    }
   },
   "id": "60a1c66ba35f0ecf",
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for prompt in prompts:\n",
    "    for dataset_folder_path in dataset_folder_paths:\n",
    "    \n",
    "        if prompt ==\"simple\" or prompt ==\"attribute_val\" or prompt ==\"plm\":\n",
    "            if prompt==\"simple\":\n",
    "                train_dataset, train_labels = parse_file(dataset_folder_path+'train.txt')\n",
    "                valid_dataset, valid_labels = parse_file(dataset_folder_path+'valid.txt') \n",
    "                test_dataset, test_labels = parse_file(dataset_folder_path+'test.txt')\n",
    "            elif prompt==\"attribute_val\":\n",
    "                train_dataset, train_labels = parse_file_att_val(dataset_folder_path+'train.txt')\n",
    "                valid_dataset, valid_labels = parse_file_att_val(dataset_folder_path+'valid.txt') \n",
    "                test_dataset, test_labels = parse_file_att_val(dataset_folder_path+'test.txt')\n",
    "            else:\n",
    "                train_dataset, train_labels = parse_file_plm(dataset_folder_path+'train.txt')\n",
    "                valid_dataset, valid_labels = parse_file_plm(dataset_folder_path+'valid.txt') \n",
    "                test_dataset, test_labels = parse_file_plm(dataset_folder_path+'test.txt')\n",
    "                \n",
    "            rows = []\n",
    "            for x,y in zip(train_dataset, train_labels):\n",
    "                rows.append(\n",
    "                    {\n",
    "                        \"e1\": x[0],\n",
    "                        \"e2\": x[1],\n",
    "                        \"answer\": [\"Yes\" if y==\"1\" else \"No\"][0],\n",
    "                    }\n",
    "                )\n",
    "            train_df = pd.DataFrame(rows)\n",
    "            \n",
    "            rows = []\n",
    "            for x,y in zip(valid_dataset, valid_labels):\n",
    "                rows.append(\n",
    "                    {\n",
    "                        \"e1\": x[0],\n",
    "                        \"e2\": x[1],\n",
    "                        \"answer\": [\"Yes\" if y==\"1\" else \"No\"][0],\n",
    "                    }\n",
    "                )\n",
    "            valid_df = pd.DataFrame(rows)\n",
    "            \n",
    "            rows = []\n",
    "            for x,y in zip(test_dataset, test_labels):\n",
    "                rows.append(\n",
    "                    {\n",
    "                        \"e1\": x[0],\n",
    "                        \"e2\": x[1],\n",
    "                        \"answer\": [\"Yes\" if y==\"1\" else \"No\"][0],\n",
    "                    }\n",
    "                )\n",
    "            test_df = pd.DataFrame(rows)\n",
    "            \n",
    "            train_df[\"text\"] = train_df.apply(format_example, axis=1)\n",
    "            valid_df[\"text\"] = valid_df.apply(format_example, axis=1)\n",
    "            test_df[\"text\"] = test_df.apply(format_example, axis=1)\n",
    "            \n",
    "        elif prompt ==\"attribute_value_dist\":\n",
    "            train_dataset, train_labels = parse_file_att_val(dataset_folder_path+'train.txt')\n",
    "            valid_dataset, valid_labels = parse_file_att_val(dataset_folder_path+'valid.txt') \n",
    "            test_dataset, test_labels = parse_file_att_val(dataset_folder_path+'test.txt')\n",
    "            \n",
    "            rows = []\n",
    "            for x,y in zip(train_dataset, train_labels):\n",
    "                rows.append(\n",
    "                    {\n",
    "                        \"e1\": x[0],\n",
    "                        \"e2\": x[1],\n",
    "                        \"distance\": x[2],\n",
    "                        \"answer\": [\"Yes\" if y==\"1\" else \"No\"][0],\n",
    "                    }\n",
    "                )\n",
    "            train_df = pd.DataFrame(rows)\n",
    "            \n",
    "            rows = []\n",
    "            for x,y in zip(valid_dataset, valid_labels):\n",
    "                rows.append(\n",
    "                    {\n",
    "                        \"e1\": x[0],\n",
    "                        \"e2\": x[1],\n",
    "                        \"distance\": x[2],\n",
    "                        \"answer\": [\"Yes\" if y==\"1\" else \"No\"][0],\n",
    "                    }\n",
    "                )\n",
    "            valid_df = pd.DataFrame(rows)\n",
    "            \n",
    "            rows = []\n",
    "            for x,y in zip(test_dataset, test_labels):\n",
    "                rows.append(\n",
    "                    {\n",
    "                        \"e1\": x[0],\n",
    "                        \"e2\": x[1],\n",
    "                        \"distance\": x[2],\n",
    "                        \"answer\": [\"Yes\" if y==\"1\" else \"No\"][0],\n",
    "                    }\n",
    "                )\n",
    "            test_df = pd.DataFrame(rows)\n",
    "\n",
    "            train_df[\"text\"] = train_df.apply(format_example_distance, axis=1)\n",
    "            valid_df[\"text\"] = valid_df.apply(format_example_distance, axis=1)\n",
    "            test_df[\"text\"] = test_df.apply(format_example_distance, axis=1)\n",
    "    \n",
    "    \n",
    "        dataset_output_path = dataset_folder_path.split('\\\\')[-3:-1]\n",
    "    \n",
    "        dataset_output_path_1, dataset_output_path_2 = dataset_output_path[0], dataset_output_path[1]\n",
    "    \n",
    "        train_out_file_path = \"datasets\\\\\"+ dataset_output_path_1 + \"_\"+ prompt + \"\\\\\"+ dataset_output_path_2+\"\\\\train.json\"\n",
    "        valid_out_file_path = \"datasets\\\\\"+ dataset_output_path_1 + \"_\"+ prompt + \"\\\\\"+ dataset_output_path_2+\"\\\\valid.json\"\n",
    "        test_out_file_path = \"datasets\\\\\"+ dataset_output_path_1 + \"_\"+ prompt + \"\\\\\"+ dataset_output_path_2+\"\\\\test.json\"\n",
    "    \n",
    "        os.makedirs(os.path.dirname(train_out_file_path), exist_ok=True)\n",
    "        os.makedirs(os.path.dirname(valid_out_file_path), exist_ok=True)\n",
    "        os.makedirs(os.path.dirname(test_out_file_path), exist_ok=True)\n",
    "    \n",
    "        train_df.to_json(train_out_file_path, orient=\"records\", lines=True)\n",
    "        valid_df.to_json(valid_out_file_path, orient=\"records\", lines=True)\n",
    "        test_df.to_json(test_out_file_path, orient=\"records\", lines=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa16f43689c3d908",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "file_path_gt = ['data\\\\GTMD\\\\mel\\\\', \n",
    "                'data\\\\GTMD\\\\sea\\\\',\n",
    "                'data\\\\GTMD\\\\sin\\\\',\n",
    "                'data\\\\GTMD\\\\tor\\\\']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-01T09:56:52.379874Z",
     "start_time": "2025-02-01T09:56:52.350877400Z"
    }
   },
   "id": "751689bed72643ee",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for prompt in prompts:    \n",
    "    for dataset_folder_path in file_path_gt:\n",
    "        train_dataset, train_labels = parse_file_plm(dataset_folder_path+'train.txt')\n",
    "        valid_dataset, valid_labels = parse_file_plm(dataset_folder_path+'valid.txt') \n",
    "        test_dataset, test_labels = parse_file_plm(dataset_folder_path+'test.txt')\n",
    "        \n",
    "        if prompt ==\"simple\" or prompt ==\"attribute_val\" or prompt ==\"plm\":\n",
    "            if prompt==\"simple\":\n",
    "                train_dataset, train_labels = parse_file(dataset_folder_path+'train.txt')\n",
    "                valid_dataset, valid_labels = parse_file(dataset_folder_path+'valid.txt') \n",
    "                test_dataset, test_labels = parse_file(dataset_folder_path+'test.txt')\n",
    "            elif prompt==\"attribute_val\":\n",
    "                train_dataset, train_labels = parse_file_att_val(dataset_folder_path+'train.txt')\n",
    "                valid_dataset, valid_labels = parse_file_att_val(dataset_folder_path+'valid.txt') \n",
    "                test_dataset, test_labels = parse_file_att_val(dataset_folder_path+'test.txt')\n",
    "            else:\n",
    "                train_dataset, train_labels = parse_file_plm(dataset_folder_path+'train.txt')\n",
    "                valid_dataset, valid_labels = parse_file_plm(dataset_folder_path+'valid.txt') \n",
    "                test_dataset, test_labels = parse_file_plm(dataset_folder_path+'test.txt')\n",
    "                \n",
    "            rows = []\n",
    "            for x,y in zip(train_dataset, train_labels):\n",
    "                rows.append(\n",
    "                    {\n",
    "                        \"e1\": x[0],\n",
    "                        \"e2\": x[1],\n",
    "                        # \"distance\": x[2],\n",
    "                        \"answer\": [\"same_as\" if y==\"1\" else \"part_of\" if y==\"2\" else \"serves\" if y==\"3\" else \"unknown\" if y==\"0\" else \"asd\"][0],\n",
    "                    }\n",
    "                )\n",
    "            train_df = pd.DataFrame(rows)\n",
    "            \n",
    "            rows = []\n",
    "            for x,y in zip(valid_dataset, valid_labels):\n",
    "                rows.append(\n",
    "                    {\n",
    "                        \"e1\": x[0],\n",
    "                        \"e2\": x[1],\n",
    "                        # \"distance\": x[2],\n",
    "                        \"answer\": [\"same_as\" if y==\"1\" else \"part_of\" if y==\"2\" else \"serves\" if y==\"3\" else \"unknown\" if y==\"0\" else \"asd\"][0],\n",
    "                    }\n",
    "                )\n",
    "            valid_df = pd.DataFrame(rows)\n",
    "            \n",
    "            rows = []\n",
    "            for x,y in zip(test_dataset, test_labels):\n",
    "                rows.append(\n",
    "                    {\n",
    "                        \"e1\": x[0],\n",
    "                        \"e2\": x[1],\n",
    "                        # \"distance\": x[2],\n",
    "                        \"answer\":  [\"same_as\" if y==\"1\" else \"part_of\" if y==\"2\" else \"serves\" if y==\"3\" else \"unknown\" if y==\"0\" else \"asd\"][0],\n",
    "                    }\n",
    "                )\n",
    "            test_df = pd.DataFrame(rows)\n",
    "            \n",
    "            if prompt==\"simple\":\n",
    "                train_df[\"text\"] = train_df.apply(format_example_gtminer_simple, axis=1)\n",
    "                valid_df[\"text\"] = valid_df.apply(format_example_gtminer_simple, axis=1)\n",
    "                test_df[\"text\"] = test_df.apply(format_example_gtminer_simple, axis=1)\n",
    "            else:\n",
    "                train_df[\"text\"] = train_df.apply(format_example_gtminer, axis=1)\n",
    "                valid_df[\"text\"] = valid_df.apply(format_example_gtminer, axis=1)\n",
    "                test_df[\"text\"] = test_df.apply(format_example_gtminer, axis=1)\n",
    "            \n",
    "            \n",
    "            \n",
    "        elif prompt =='attribute_value_dist':\n",
    "            \n",
    "            train_dataset, train_labels = parse_file_att_val(dataset_folder_path+'train.txt')\n",
    "            valid_dataset, valid_labels = parse_file_att_val(dataset_folder_path+'valid.txt') \n",
    "            test_dataset, test_labels = parse_file_att_val(dataset_folder_path+'test.txt')\n",
    "            \n",
    "            rows = []\n",
    "            for x,y in zip(train_dataset, train_labels):\n",
    "                rows.append(\n",
    "                    {\n",
    "                        \"e1\": x[0],\n",
    "                        \"e2\": x[1],\n",
    "                        \"distance\": x[2],\n",
    "                        \"answer\": [\"same_as\" if y==\"1\" else \"part_of\" if y==\"2\" else \"serves\" if y==\"3\" else \"unknown\" if y==\"0\" else \"asd\"][0],\n",
    "                    }\n",
    "                )\n",
    "            train_df = pd.DataFrame(rows)\n",
    "            \n",
    "            rows = []\n",
    "            for x,y in zip(valid_dataset, valid_labels):\n",
    "                rows.append(\n",
    "                    {\n",
    "                        \"e1\": x[0],\n",
    "                        \"e2\": x[1],\n",
    "                        \"distance\": x[2],\n",
    "                        \"answer\": [\"same_as\" if y==\"1\" else \"part_of\" if y==\"2\" else \"serves\" if y==\"3\" else \"unknown\" if y==\"0\" else \"asd\"][0],\n",
    "                    }\n",
    "                )\n",
    "            valid_df = pd.DataFrame(rows)\n",
    "            \n",
    "            rows = []\n",
    "            for x,y in zip(test_dataset, test_labels):\n",
    "                rows.append(\n",
    "                    {\n",
    "                        \"e1\": x[0],\n",
    "                        \"e2\": x[1],\n",
    "                        \"distance\": x[2],\n",
    "                        \"answer\":  [\"same_as\" if y==\"1\" else \"part_of\" if y==\"2\" else \"serves\" if y==\"3\" else \"unknown\" if y==\"0\" else \"asd\"][0],\n",
    "                    }\n",
    "                )\n",
    "            test_df = pd.DataFrame(rows)\n",
    "            \n",
    "            train_df[\"text\"] = train_df.apply(format_example_gtminer_distance, axis=1)\n",
    "            valid_df[\"text\"] = valid_df.apply(format_example_gtminer_distance, axis=1)\n",
    "            test_df[\"text\"] = test_df.apply(format_example_gtminer_distance, axis=1)\n",
    "            \n",
    "            \n",
    "        \n",
    "        dataset_output_path = dataset_folder_path.split('\\\\')[-3:-1]\n",
    "        \n",
    "        dataset_output_path_1, dataset_output_path_2 = dataset_output_path[0], dataset_output_path[1]\n",
    "        \n",
    "        train_out_file_path = \"datasets\\\\\"+ dataset_output_path_1 +\"_\"+ prompt+ \"\\\\\"+ dataset_output_path_2+\"\\\\train.json\"\n",
    "        valid_out_file_path = \"datasets\\\\\"+ dataset_output_path_1 +\"_\"+ prompt+ \"\\\\\"+ dataset_output_path_2+\"\\\\valid.json\"\n",
    "        test_out_file_path = \"datasets\\\\\"+ dataset_output_path_1 +\"_\"+ prompt+ \"\\\\\"+ dataset_output_path_2+\"\\\\test.json\"\n",
    "        \n",
    "        os.makedirs(os.path.dirname(train_out_file_path), exist_ok=True)\n",
    "        os.makedirs(os.path.dirname(valid_out_file_path), exist_ok=True)\n",
    "        os.makedirs(os.path.dirname(test_out_file_path), exist_ok=True)\n",
    "        \n",
    "        train_df.to_json(train_out_file_path, orient=\"records\", lines=True)\n",
    "        valid_df.to_json(valid_out_file_path, orient=\"records\", lines=True)\n",
    "        test_df.to_json(test_out_file_path, orient=\"records\", lines=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-01T10:02:19.968926800Z",
     "start_time": "2025-02-01T10:01:39.376989300Z"
    }
   },
   "id": "d463750a0c5d19a7",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "42c457edf717c6e3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
