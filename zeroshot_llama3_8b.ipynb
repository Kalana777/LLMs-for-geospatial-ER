{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-01T10:15:03.620969300Z",
     "start_time": "2025-02-01T10:15:03.615970500Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, set_seed, Trainer, TrainingArguments, BitsAndBytesConfig, \\\n",
    "    DataCollatorForLanguageModeling, Trainer, TrainingArguments, logging\n",
    "from torch import cuda, bfloat16\n",
    "import transformers\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from metrics import calc_mets_my"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "PROJECT = \"Llama3-8B-QLora-Omni\"\n",
    "MODEL_NAME = 'meta-llama/Meta-Llama-3-8B-Instruct'\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-12T08:47:48.893036700Z",
     "start_time": "2025-01-12T08:47:48.877037Z"
    }
   },
   "id": "717a14b47b432706",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'cuda:0'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-12T08:47:48.945038900Z",
     "start_time": "2025-01-12T08:47:48.887036300Z"
    }
   },
   "id": "84893e79016722b0",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=bfloat16\n",
    ")\n",
    "\n",
    "\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    token=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-12T08:47:49.776047800Z",
     "start_time": "2025-01-12T08:47:48.934040900Z"
    }
   },
   "id": "4a0dd64fdc5cbfbe",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c0894cc05fa14563bc9d10dd9716890f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(128256, 4096)\n    (layers): ModuleList(\n      (0-31): 32 x LlamaDecoderLayer(\n        (self_attn): LlamaSdpaAttention(\n          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    trust_remote_code=True,\n",
    "    config=model_config,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='auto',\n",
    "    token=True\n",
    ")\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-12T08:48:58.352921200Z",
     "start_time": "2025-01-12T08:47:49.768029600Z"
    }
   },
   "id": "1145fa5b1ec3e832",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    token=True\n",
    ")\n",
    "PAD_TOKEN = tokenizer.eos_token\n",
    "tokenizer.add_special_tokens({\"pad_token\": PAD_TOKEN})\n",
    "tokenizer.padding_side = \"right\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-12T08:48:59.520524600Z",
     "start_time": "2025-01-12T08:48:58.367921300Z"
    }
   },
   "id": "b5eea3353549e3e9",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory footprint: 5.207535028457642 GB\n"
     ]
    }
   ],
   "source": [
    "memory_used = model.get_memory_footprint()\n",
    "print(\"Memory footprint: {} GB\".format(memory_used/1024/1024/1024))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e406f14be9fe68e7",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def parse_file(file_path):\n",
    "    \"\"\"\n",
    "    Parses the input file and extracts entity pairs and labels.\n",
    "    :param file_path: Path to the input text file.\n",
    "    :return: A list of tuples (entity_1, entity_2, label).\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    labels=[]\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            parts = line.strip().split(\"\\t\")\n",
    "            entity_1 = parts[0].replace(\"COL \", \"\").replace(\"[VAL] \", \"\").replace(\"VAL \", \"\").replace(\"name \", \"\").replace(\"type \", \"\").replace(\"latitude \", \"\").replace(\"longitude \", \"\").replace(\"postalCode \", \"\").replace(\"address \", \"\").strip()\n",
    "            entity_2 = parts[1].replace(\"COL \", \"\").replace(\"[VAL] \", \"\").replace(\"VAL \", \"\").replace(\"name \", \"\").replace(\"type \", \"\").replace(\"latitude \", \"\").replace(\"longitude \", \"\").replace(\"postalCode \", \"\").replace(\"address \", \"\").strip()\n",
    "            label = parts[2]  # Assuming the label is at the end of each line\n",
    "            data.append((entity_1, entity_2))\n",
    "            labels.append(label)\n",
    "    return data, labels"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b572fcabc396d2c4",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def prepare_prompt_simple(row):\n",
    "    \"\"\"\n",
    "    Prepares a natural language prompt for the entity resolution task.\n",
    "    :param row: A tuple with two entities and the expected result.\n",
    "    :return: A formatted prompt string.\n",
    "    \"\"\"\n",
    "    \n",
    "    entity_1, entity_2 = row\n",
    "    # print(entity_1)\n",
    "    prompt = f\"\"\"Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.\n",
    "    Place 1: {entity_1}\n",
    "    Place 2: {entity_2}\n",
    "    Answer: \"\"\"\n",
    "    return prompt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-03T10:58:09.480718300Z",
     "start_time": "2025-01-03T10:58:09.465718700Z"
    }
   },
   "id": "2c1a5fad3e3a9cb0",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def prepare_prompt_attribute_value(row):\n",
    "    \"\"\"\n",
    "    Prepares a natural language prompt for the entity resolution task.\n",
    "    :param row: A tuple with two entities and the expected result.\n",
    "    :return: A formatted prompt string.\n",
    "    \"\"\"\n",
    "    \n",
    "    entity_1, entity_2 = row\n",
    "    # print(entity_1)\n",
    "    prompt = f\"\"\"Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.\n",
    "    Place 1: {entity_1}\n",
    "    Place 2: {entity_2}\n",
    "    Answer: \"\"\"\n",
    "    return prompt"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c40163da93bbb941"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "logging.set_verbosity_error()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-03T10:58:09.496714400Z",
     "start_time": "2025-01-03T10:58:09.474718100Z"
    }
   },
   "id": "4d439e4e53b585fb",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def zero_shot_inference(model, tokenizer, prompts, max_new_tokens):\n",
    "    \"\"\"\n",
    "    Performs zero-shot inference using the model.\n",
    "    :param model: The loaded quantized model.\n",
    "    :param tokenizer: Tokenizer for the model.\n",
    "    :param prompts: List of input prompts.\n",
    "    :return: Model predictions (Yes/No).\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for prompt in prompts:\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "        # outputs = model.pipeline(inputs.input_ids)\n",
    "        outputs = model.generate(\n",
    "            inputs.input_ids, \n",
    "            max_length=100,  # Maximum length of the generated text\n",
    "            max_new_tokens= max_new_tokens,\n",
    "            num_return_sequences=1,  # Number of sequences to generate\n",
    "            no_repeat_ngram_size=2,  # Avoid repeating phrases\n",
    "            temperature=0.01,  # Controls randomness; lower is less random\n",
    "            top_k=50,  # Top-k sampling\n",
    "        )\n",
    "        prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        # prediction = tokenizer.decode(outputs[:, inputs.shape[1]:])\n",
    "        results.append(prediction.strip())\n",
    "        \n",
    "    return results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-23T03:33:59.084241Z",
     "start_time": "2024-12-23T03:33:59.049241900Z"
    }
   },
   "id": "8cb921151e0059dd",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "file_paths = [\"C:\\\\Users\\kwijegun\\PycharmProjects\\omni-geometry-geoER\\data\\\\train_valid_test\\my_data\\\\auck\\\\test.txt\", \"C:\\\\Users\\kwijegun\\PycharmProjects\\omni-geometry-geoER\\data\\\\train_valid_test\\my_data\\\\hope\\\\test.txt\", \"C:\\\\Users\\kwijegun\\PycharmProjects\\omni-geometry-geoER\\data\\\\train_valid_test\\my_data\\\\norse\\\\test.txt\", \"C:\\\\Users\\kwijegun\\PycharmProjects\\omni-geometry-geoER\\data\\\\train_valid_test\\my_data\\\\north\\\\test.txt\", \"C:\\\\Users\\kwijegun\\PycharmProjects\\omni-geometry-geoER\\data\\\\train_valid_test\\my_data\\\\palm\\\\test.txt\", \"C:\\\\Users\\kwijegun\\PycharmProjects\\omni-geometry-geoER\\data\\\\train_valid_test\\\\osm_fsq\\\\edi\\\\test.txt\", \"C:\\\\Users\\kwijegun\\PycharmProjects\\omni-geometry-geoER\\data\\\\train_valid_test\\\\osm_fsq\\\\pit\\\\test.txt\", \"C:\\\\Users\\kwijegun\\PycharmProjects\\omni-geometry-geoER\\data\\\\train_valid_test\\\\osm_fsq\\\\sin\\\\test.txt\",\"C:\\\\Users\\kwijegun\\PycharmProjects\\omni-geometry-geoER\\data\\\\train_valid_test\\\\osm_fsq\\\\tor\\\\test.txt\",\"C:\\\\Users\\kwijegun\\PycharmProjects\\omni-geometry-geoER\\data\\\\train_valid_test\\\\osm_yelp\\\\edi\\\\test.txt\",\"C:\\\\Users\\kwijegun\\PycharmProjects\\omni-geometry-geoER\\data\\\\train_valid_test\\\\osm_yelp\\\\pit\\\\test.txt\",\"C:\\\\Users\\kwijegun\\PycharmProjects\\omni-geometry-geoER\\data\\\\train_valid_test\\\\osm_yelp\\\\sin\\\\test.txt\",\"C:\\\\Users\\kwijegun\\PycharmProjects\\omni-geometry-geoER\\data\\\\train_valid_test\\\\osm_yelp\\\\tor\\\\test.txt\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-22T10:57:28.141969600Z",
     "start_time": "2024-12-22T10:57:28.121013600Z"
    }
   },
   "id": "29988894e7afdb3e",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataset_folder_path = ['datasets\\\\my_data_distance\\\\auck\\\\', 'datasets\\\\my_data_distance\\\\hope\\\\', 'datasets\\\\my_data_distance\\\\norse\\\\','datasets\\\\my_data_distance\\\\north\\\\', 'datasets\\\\my_data_distance\\\\palm\\\\', 'datasets\\\\osm_fsq_distance\\\\edi\\\\', 'datasets\\\\osm_fsq_distance\\\\pit\\\\', 'datasets\\\\osm_fsq_distance\\\\sin\\\\', 'datasets\\\\osm_fsq_distance\\\\tor\\\\', 'datasets\\\\osm_yelp_distance\\\\edi\\\\', 'datasets\\\\osm_yelp_distance\\\\pit\\\\', 'datasets\\\\osm_yelp_distance\\\\sin\\\\', 'datasets\\\\osm_yelp_distance\\\\tor\\\\', 'datasets\\\\acheson_distance\\\\swiss\\\\']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-03T11:00:45.780580400Z",
     "start_time": "2025-01-03T11:00:45.756579800Z"
    }
   },
   "id": "c421837cbbcff5f7",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def calculate_metrics(predictions, labels):\n",
    " \n",
    "    # Convert \"Yes\" to 1 and \"No\" to 0 for predicted labels\n",
    "    predicted = [1 if label == \"Yes\" else 0 if label == \"No\" else 3 for label in predictions]\n",
    "    \n",
    "    # Ensure ground truth is already in binary format\n",
    "    ground_truth = [int(x) for x in labels]\n",
    "    # Calculate metrics\n",
    "    precision = precision_score(ground_truth, predicted)\n",
    "    recall = recall_score(ground_truth, predicted)\n",
    "    f1 = f1_score(ground_truth, predicted)\n",
    "    \n",
    "    return {\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-22T10:57:28.455972700Z",
     "start_time": "2024-12-22T10:57:28.451970700Z"
    }
   },
   "id": "b7723a5d16c9abcb",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my_data', 'auck', 'test.txt']\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.\n",
      "    Place 1: Tautini farmstead -40.18825 176.14021\n",
      "    Place 2: Waikoukou Stream Stream -40.08742665596005 176.28878276483226\n",
      "    Answer: \n",
      "0\n",
      "601 601\n",
      "{'Precision': 0.5555555555555556, 'Recall': 0.75, 'F1 Score': 0.6382978723404256}\n",
      "['my_data', 'hope', 'test.txt']\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.\n",
      "    Place 1: Silver Stream stream -44.04833 168.67008\n",
      "    Place 2: Deep Dale Valley -44.025083 168.672056\n",
      "    Answer: \n",
      "0\n",
      "2907 2907\n",
      "{'Precision': 0.7865168539325843, 'Recall': 0.625, 'F1 Score': 0.6965174129353234}\n",
      "['my_data', 'norse', 'test.txt']\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.\n",
      "    Place 1: Mangatewai River Scenic Reserve Scenic Reserve -39.985556 176.254722\n",
      "    Place 2: Ōtāwhao locality -40.0501529 176.2682748\n",
      "    Answer: \n",
      "0\n",
      "1783 1783\n",
      "{'Precision': 0.6808510638297872, 'Recall': 0.7111111111111111, 'F1 Score': 0.6956521739130435}\n",
      "['my_data', 'north', 'test.txt']\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.\n",
      "    Place 1: Waitiki Channel stream -34.51818 172.88018\n",
      "    Place 2: Matapia Island -34.606333571762384 172.79844153380557\n",
      "    Answer: \n",
      "0\n",
      "3452 3452\n",
      "{'Precision': 0.6607142857142857, 'Recall': 0.8809523809523809, 'F1 Score': 0.7551020408163265}\n",
      "['my_data', 'palm', 'test.txt']\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.\n",
      "    Place 1: Guy Avenue residential -40.34778395292905 175.6002199480078\n",
      "    Place 2: Argyle Avenue residential -40.34934954465575 175.60141052181092\n",
      "    Answer: \n",
      "0\n",
      "1191 1191\n",
      "{'Precision': 0.5945945945945946, 'Recall': 0.5789473684210527, 'F1 Score': 0.5866666666666667}\n",
      "['osm_fsq', 'edi', 'test.txt']\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.\n",
      "    Place 1: Grace North Edinburgh 55.96494943189891 -3.196916036169164 Logie Green Rd, 64 EH7 4HQ\n",
      "    Place 2: Crombies of Edinburgh 55.95861906805779 -3.19005780781009 97-101 Broughton St EH1 3RZ\n",
      "    Answer: \n",
      "0\n",
      "5216 5216\n",
      "{'Precision': 0.8469387755102041, 'Recall': 0.5781094527363184, 'F1 Score': 0.6871673565937315}\n",
      "['osm_fsq', 'pit', 'test.txt']\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.\n",
      "    Place 1: Panther Hall 40.44498734340524 -79.96209824445856 nan nan\n",
      "    Place 2: Panther Hollow Lot 40.4404019017384 -79.95040009542119 8 Boundary Street 15260\n",
      "    Answer: \n",
      "0\n",
      "1502 1502\n",
      "{'Precision': 0.8194945848375451, 'Recall': 0.5194508009153318, 'F1 Score': 0.6358543417366946}\n",
      "['osm_fsq', 'sin', 'test.txt']\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.\n",
      "    Place 1: Garden Apartments 1.3123865010572997 103.82490180924768 nan nan\n",
      "    Place 2: Le Grove Apartments 1.3133607473862063 103.82573283698127 32 Orange Grove Rd nan\n",
      "    Answer: \n",
      "0\n",
      "5774 5774\n",
      "{'Precision': 0.4165497896213184, 'Recall': 0.4618973561430793, 'F1 Score': 0.43805309734513276}\n",
      "['osm_fsq', 'tor', 'test.txt']\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.\n",
      "    Place 1: Bloor Collegiate Institute 43.65892111180895 -79.43699172520552 Bloor Street West, 1141 M6H 1M9\n",
      "    Place 2: Harbord Collegiate Institute 43.661708714364735 -79.41400876604314 286 Harbord St., at Euclid Ave. M6G 1G5\n",
      "    Answer: \n",
      "0\n",
      "5359 5359\n",
      "{'Precision': 0.8707964601769912, 'Recall': 0.42159383033419023, 'F1 Score': 0.5681293302540416}\n",
      "['osm_yelp', 'edi', 'test.txt']\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.\n",
      "    Place 1: The Square 55.956014 -3.1919268 North St Andrew Street, 17 nan\n",
      "    Place 2: The Cupboard 55.9495698 -3.211894 10 William Street EH3 7NH\n",
      "    Answer: \n",
      "0\n",
      "5621 5621\n",
      "{'Precision': 0.907051282051282, 'Recall': 0.8167388167388168, 'F1 Score': 0.8595292331055429}\n",
      "['osm_yelp', 'pit', 'test.txt']\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.\n",
      "    Place 1: Cafe Du Jour 40.42908668865597 -79.98694189998093 East Carson Street, 1107 15203\n",
      "    Place 2: Cafe Euro 40.441532 -79.995221 600 Grant St 15219.0\n",
      "    Answer: \n",
      "0\n",
      "1536 1536\n",
      "{'Precision': 0.8033240997229917, 'Recall': 0.5954825462012321, 'F1 Score': 0.6839622641509434}\n",
      "['osm_yelp', 'sin', 'test.txt']\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.\n",
      "    Place 1: Forum Restaurant 1.2866651 103.8494922 nan nan\n",
      "    Place 2: Shin Yeh Restaurant 1.29153954075445 103.844539672136 177 River Valley Road, #02-19, Liang Court 179030.0\n",
      "    Answer: \n",
      "0\n",
      "6478 6478\n",
      "{'Precision': 0.5608194622279129, 'Recall': 0.4960362400906002, 'F1 Score': 0.5264423076923077}\n",
      "['osm_yelp', 'tor', 'test.txt']\n",
      "Do the two place descriptions refer to the same real-world place? Answer with 'Yes' if they do and 'No' if they do not.\n",
      "    Place 1: Mister Tasty's Restaurant 43.6887671 -79.2969779 nan nan\n",
      "    Place 2: Sandy's Restaurant 43.6855652 -79.3122921 2093 Danforth Ave M4C 1K1\n",
      "    Answer: \n",
      "0\n",
      "8391 8391\n",
      "{'Precision': 0.9026915113871635, 'Recall': 0.5356265356265356, 'F1 Score': 0.6723207401696222}\n"
     ]
    }
   ],
   "source": [
    "# File path to the input data\n",
    "for file_path in dataset_folder_path:\n",
    "    \n",
    "    print(file_path.split('\\\\')[-3:])\n",
    "    data, labels = parse_file(file_path)\n",
    "    prompts = [prepare_prompt_simple(row) for row in data]\n",
    "    print(prompts[0])\n",
    "    print(labels[0])\n",
    "    predictions = zero_shot_inference(model, tokenizer, prompts, 1)\n",
    "    predictions = [x.split(\" \")[-1].strip() for x in predictions] \n",
    "    print(len(predictions), len(labels))\n",
    "    print(calculate_metrics(predictions, labels))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-22T12:57:13.031995500Z",
     "start_time": "2024-12-22T10:57:29.116966500Z"
    }
   },
   "id": "6fc57c609c25ec84",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def prepare_prompt_gtminer(row):\n",
    "    \"\"\"\n",
    "    Prepares a natural language prompt for the entity resolution task.\n",
    "    :param row: A tuple with two entities and the expected result.\n",
    "    :return: A formatted prompt string.\n",
    "    \"\"\"\n",
    "    \n",
    "    entity_1, entity_2 = row\n",
    "    # print(entity_1)\n",
    "    prompt = f\"\"\"Two place descriptions are provided. Answer with 'same_as' if the first place is the same as the second place. Answer with 'part_of' if the first place is a part of the second place and is located inside the second place. Answer with 'serves' if the first place provides a service to the second place in terms of human mobility, assistance, etc. Answer with 'unknown' if the two places show none of these relations.\n",
    "    Place 1: {entity_1}\n",
    "    Place 2: {entity_2}\n",
    "    Answer: \"\"\"\n",
    "    \n",
    "    return prompt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-23T03:56:13.660141700Z",
     "start_time": "2024-12-23T03:56:13.628144100Z"
    }
   },
   "id": "3d8340c4b05fe6e3",
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def calculate_metrics2(predictions, labels):\n",
    "    tot_p = 0\n",
    "    true_p = 0\n",
    "    pred_p = 0\n",
    "    \n",
    "    valid_y_tensor = [int(x) for x in labels]\n",
    "    y_pred = [1 if label == \"same_as\" or \"same\" else 2 if label == \"part_of\" else 3 if label == \"serves\" else 0 if label ==\"unknown\" else 4 for label in predictions]\n",
    "\n",
    "    for i in range(len(y_pred)):\n",
    "\n",
    "        if valid_y_tensor[i] > 0:\n",
    "            tot_p += 1\n",
    "\n",
    "            if y_pred[i] == valid_y_tensor[i]:\n",
    "                true_p += 1\n",
    "\n",
    "        if y_pred[i] > 0:\n",
    "            pred_p += 1\n",
    "\n",
    "    f1 = 0.0\n",
    "    prec = 0.0\n",
    "    rec = 0.0\n",
    "\n",
    "    if tot_p and pred_p:\n",
    "        rec = true_p / tot_p\n",
    "        prec = true_p / pred_p\n",
    "\n",
    "        if rec > 0 or prec > 0:\n",
    "            f1 = 2 * prec * rec / (prec + rec)\n",
    "\n",
    "    print('P: ' + str(round(prec, 4)) + '  |  R: ' + str(round(rec, 4)) + '  |  F1: ' + str(round(f1, 4)))\n",
    "\n",
    "    return {\n",
    "        'precision': prec,\n",
    "        'recall': rec,\n",
    "        'f1': f1\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-23T03:56:14.468135100Z",
     "start_time": "2024-12-23T03:56:14.444142200Z"
    }
   },
   "id": "2411c1a515146a9a",
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gtminer', 'mel', 'test.txt']\n",
      "Two place descriptions are provided. Answer with 'same_as' if the first place is the same as the second place. Answer with 'part_of' if the first place is a part of the second place and is located inside the second place. Answer with 'serves' if the first place provides a service to the second place in terms of human mobility, assistance, etc. Answer with 'unknown' if the two places show none of these relations.\n",
      "    Place 1: JB Hi-Fi electronics nan -37.7681204 145.304855\n",
      "    Place 2: Chirnside Homemaker Centre mall 282 Maroondah Highway 3116 -37.7663845 145.3058855\n",
      "    Answer: \n",
      "2\n",
      "1839 1839\n",
      "P: 0.0984  |  R: 0.1613  |  F1: 0.1223\n",
      "{'precision': 0.09842305600870038, 'recall': 0.16131907308377896, 'f1': 0.12225599459642011}\n",
      "['gtminer', 'sea', 'test.txt']\n",
      "Two place descriptions are provided. Answer with 'same_as' if the first place is the same as the second place. Answer with 'part_of' if the first place is a part of the second place and is located inside the second place. Answer with 'serves' if the first place provides a service to the second place in terms of human mobility, assistance, etc. Answer with 'unknown' if the two places show none of these relations.\n",
      "    Place 1: 32 Bar & Grill Sports Bars; American (Traditional) nan 47.70645953432845 -122.3245641011371\n",
      "    Place 2: Kraken Community Iceplex leisure 10601 5th Avenue Northeast 98125 47.7062215 -122.3251917\n",
      "    Answer: \n",
      "2\n",
      "4747 4747\n",
      "P: 0.0613  |  R: 0.1488  |  F1: 0.0868\n",
      "{'precision': 0.0613018748683379, 'recall': 0.14884910485933503, 'f1': 0.08683974932855865}\n",
      "['gtminer', 'sin', 'test.txt']\n",
      "Two place descriptions are provided. Answer with 'same_as' if the first place is the same as the second place. Answer with 'part_of' if the first place is a part of the second place and is located inside the second place. Answer with 'serves' if the first place provides a service to the second place in terms of human mobility, assistance, etc. Answer with 'unknown' if the two places show none of these relations.\n",
      "    Place 1: Garrett Gourmet Popcorn Candy Stores 541 Orchard Rd #01-K1 Liat Towers 238881 1.3053032 103.8305236\n",
      "    Place 2: Liat Towers Shopping Centers 541 Orch Rd 238881 1.3051056 103.8307274\n",
      "    Answer: \n",
      "2\n",
      "7852 7852\n",
      "P: 0.0582  |  R: 0.1199  |  F1: 0.0784\n",
      "{'precision': 0.058201732042791644, 'recall': 0.11988457502623295, 'f1': 0.078360768175583}\n",
      "['gtminer', 'tor', 'test.txt']\n",
      "Two place descriptions are provided. Answer with 'same_as' if the first place is the same as the second place. Answer with 'part_of' if the first place is a part of the second place and is located inside the second place. Answer with 'serves' if the first place provides a service to the second place in terms of human mobility, assistance, etc. Answer with 'unknown' if the two places show none of these relations.\n",
      "    Place 1: New College Library library 20 Willcocks Street 43.6617897 -79.4001637\n",
      "    Place 2: Engineering Library library nan 43.6601686 -79.3949804\n",
      "    Answer: \n",
      "0\n",
      "5101 5101\n",
      "P: 0.0574  |  R: 0.1231  |  F1: 0.0783\n",
      "{'precision': 0.05743971770241129, 'recall': 0.123109243697479, 'f1': 0.07833177382702847}\n"
     ]
    }
   ],
   "source": [
    "file_path_gt = ['C:\\\\Users\\kwijegun\\PycharmProjects\\omni-geometry-geoER\\data\\\\train_valid_test\\gtminer\\\\mel\\\\test.txt', 'C:\\\\Users\\kwijegun\\PycharmProjects\\omni-geometry-geoER\\data\\\\train_valid_test\\gtminer\\\\sea\\\\test.txt','C:\\\\Users\\kwijegun\\PycharmProjects\\omni-geometry-geoER\\data\\\\train_valid_test\\gtminer\\\\sin\\\\test.txt','C:\\\\Users\\kwijegun\\PycharmProjects\\omni-geometry-geoER\\data\\\\train_valid_test\\gtminer\\\\tor\\\\test.txt']\n",
    "\n",
    "for file_name in file_path_gt:\n",
    "    \n",
    "    print(file_name.split('\\\\')[-3:])\n",
    "    data, labels = parse_file(file_name)\n",
    "    prompts = [prepare_prompt_gtminer(row) for row in data]\n",
    "    print(prompts[0])\n",
    "    print(labels[0])\n",
    "    predictions = zero_shot_inference(model, tokenizer, prompts, 2)\n",
    "    predictions = [x.split(\" \")[-1].strip() for x in predictions] \n",
    "    print(len(predictions), len(labels))\n",
    "    print(calc_mets_my(predictions, labels))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-23T11:39:40.317365400Z",
     "start_time": "2024-12-23T10:17:26.153609400Z"
    }
   },
   "id": "66e4bbbfd4ed9de7",
   "execution_count": 76
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
